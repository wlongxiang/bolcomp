{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "square-skating",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-coordination",
   "metadata": {},
   "source": [
    "# Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-adventure",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install -U pip\n",
    "!python3 -m pip install -U setuptools wheel\n",
    "\n",
    "# Here we assume CUDA 10.1 is installed.  You should change the number\n",
    "# according to your own CUDA version (e.g. mxnet_cu100 for CUDA 10.0).\n",
    "!python3 -m pip install -U \"mxnet_cu101<2.0.0\"\n",
    "!python3 -m pip install -U autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complete-brunswick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "korean-electricity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unwanted</th>\n",
       "      <th>ProductTitleNL</th>\n",
       "      <th>ProductDescriptionNL</th>\n",
       "      <th>BrickName</th>\n",
       "      <th>ChunkName</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Material</th>\n",
       "      <th>NumberOfProductsInPackage</th>\n",
       "      <th>PackageHeight</th>\n",
       "      <th>...</th>\n",
       "      <th>text_758</th>\n",
       "      <th>text_759</th>\n",
       "      <th>text_760</th>\n",
       "      <th>text_761</th>\n",
       "      <th>text_762</th>\n",
       "      <th>text_763</th>\n",
       "      <th>text_764</th>\n",
       "      <th>text_765</th>\n",
       "      <th>text_766</th>\n",
       "      <th>text_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>Luxe Ginder- Zwart</td>\n",
       "      <td>4-delig grinder (51mm diameter).\\nDeze grinder heeft glazen zij kanten zo dat je de kief voorraad kan zien groeien .\\nZwart/Zilver/Rood.</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>DeSmokerShop</td>\n",
       "      <td>Zwart</td>\n",
       "      <td>Metaal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154095</td>\n",
       "      <td>0.527087</td>\n",
       "      <td>-0.065295</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.412198</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.741614</td>\n",
       "      <td>0.330917</td>\n",
       "      <td>-0.036481</td>\n",
       "      <td>1.079142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Jacob Hooy Valeriaanwortel gemalen</td>\n",
       "      <td>Jacob Hooy Valeriaanwortel gemalen</td>\n",
       "      <td>Keuken Snij-/Rasp-/Haktoestellen</td>\n",
       "      <td>Keukenmolen</td>\n",
       "      <td>Jacob Hooy</td>\n",
       "      <td>Wit</td>\n",
       "      <td>Katoen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341660</td>\n",
       "      <td>0.481505</td>\n",
       "      <td>0.279541</td>\n",
       "      <td>-0.391992</td>\n",
       "      <td>-0.713672</td>\n",
       "      <td>0.319069</td>\n",
       "      <td>-0.177490</td>\n",
       "      <td>-0.340997</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>-0.326661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>SOG Bladelight Fixed Blade</td>\n",
       "      <td>&lt;p&gt; SOG Bladelight Folder Uniek zakmes met verlichting!&lt;br /&gt;6 felle LED lampjes verlichten het snijvlak of zijn gewoon handig als zaklamp.&lt;br /&gt;Compleet met AAA batterij en etui. &lt;/p&gt; KleurZwart met grijsHardheid57RcTotale lengte23.5 cmLengte lemmet11.5 cmModel lemmetClip PointLengte handgreep11.3 cmMateriaal handgreepGlass-Reinforced NylonStaalsoort8Cr13MoVAantal batterijen1Soort batterijenAA AlkalineBrandduur lamp2 uurSoort lampLEDLichtopbrengst30 lumenEtuiNylon</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>SOG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571482</td>\n",
       "      <td>0.515193</td>\n",
       "      <td>0.046478</td>\n",
       "      <td>-0.109512</td>\n",
       "      <td>0.473507</td>\n",
       "      <td>-0.113991</td>\n",
       "      <td>0.682185</td>\n",
       "      <td>0.303920</td>\n",
       "      <td>0.217693</td>\n",
       "      <td>1.066162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>Nedis CCBW39300WT20 Data- En Oplaadkabel Apple Lightning 8-pins Male - Usb A Male 2,0 M Wit</td>\n",
       "      <td>Kabel om een iPhone, iPad of iPod te verbinden met een PC om data te verzenden en te laden.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;AWG-waarde: 30 / 22&lt;/li&gt;&lt;li&gt;Conductormateriaal: Koper&lt;/li&gt;&lt;li&gt;Connectie A: Apple Lightning&lt;/li&gt;&lt;li&gt;Connectie B: USB A Male&lt;/li&gt;&lt;li&gt;Connectordesign - kant A: Recht&lt;/li&gt;&lt;li&gt;Connectordesign - Kant B: Recht&lt;/li&gt;&lt;li&gt;Diameter: 3.1 mm&lt;/li&gt;&lt;li&gt;Kabelontwerp: Rond&lt;/li&gt;&lt;li&gt;Kleur: Wit&lt;/li&gt;&lt;li&gt;Lengte: 2.00 m&lt;/li&gt;&lt;li&gt;Materiaal buitenkant: PVC&lt;/li&gt;&lt;li&gt;Type connectorplating: Nikkel&lt;/li&gt;&lt;li&gt;Type kabel: Apple Lightning 8-Pins&lt;/li&gt;&lt;/ul&gt;</td>\n",
       "      <td>Opladers</td>\n",
       "      <td>Batterijoplader</td>\n",
       "      <td>Nedis</td>\n",
       "      <td>Wit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575893</td>\n",
       "      <td>0.578776</td>\n",
       "      <td>0.754166</td>\n",
       "      <td>-0.215556</td>\n",
       "      <td>0.388041</td>\n",
       "      <td>-0.159984</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.487187</td>\n",
       "      <td>0.043950</td>\n",
       "      <td>0.315264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>Cold Steel Two Handed Latin</td>\n",
       "      <td>&lt;p&gt; Two handed Latin Machete.&lt;br /&gt;dubbelhandig te gebruiken voor het zwaardere kapwerk. &lt;/p&gt; KleurZwart Hardheid57Rc Totale lengte74.5 cm Model lemmetTanto Point Materiaal handgreepKunststof StaalsoortNiet roestvrij-Carbons Staal</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Cold Steel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229359</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>-0.085757</td>\n",
       "      <td>-0.079637</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>0.480540</td>\n",
       "      <td>0.333043</td>\n",
       "      <td>0.283477</td>\n",
       "      <td>1.007419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>N</td>\n",
       "      <td>Gift House international Pocket Multi Tool Zakmes</td>\n",
       "      <td>Met de IGGI Pocket Multi Tool op zak heb je altijd je gereedschap bij de hand! Deze Pocket Multi Tool heeft de afmetingen van een creditcard, dus perfect mee te nemen in je portefeuille en heeft 10 verschillende functies: een blikopener, snijrand, schroevendraaier, liniaal (5 cm), flesopener, 2-positie en 4-positie sleutel (voor verschillende maten van moeren en bouten), vlinder schroefsleutel, zaag en hulpsleutel. De Multi Tool is gemaakt van RVS en wordt geleverd met een bijbehorend plastic beschermhoesje.&lt;br /&gt;Geweldig handig om bij je te hebben tijdens kamperen, vissen, fietsen of ande...</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Gift House International</td>\n",
       "      <td>Multicolour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483081</td>\n",
       "      <td>0.617548</td>\n",
       "      <td>0.778052</td>\n",
       "      <td>-0.272631</td>\n",
       "      <td>0.148481</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.754632</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>-0.286155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>N</td>\n",
       "      <td>Anti Blaf Apparaat  – Honden - Blaf Afstotend  – Veilig En Stopt Agressie &amp; Blaffen -  Anti Blaffen - Diervriendelijk Anti Blaf Apparaat - Bruin</td>\n",
       "      <td>&lt;h3&gt;&lt;strong&gt;Broomer Anti Blaf Apparaat tegen irritant geblaf&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt; Altijd al op zoek geweest naar een diervriendelijke methode om je hond te trainen en het irritante blaffen en ongewenst gedrag af te leren? Dan ben je bij Broomer aan het juiste adres! Met dit anti blaf apparaat voorkom je problemen met de buren. Het geblaf van jouw hond zal worden beperkt door de ultrasone frequentie. Met dit hoogwaardige ultrasoon geluid van dit anti-blaf apparaat stopt jouw hond met blaffen. Dit anti-blaf apparaat van Broomer is veilig en stopt agressie en blaffen. &lt;/p&gt;&lt;p&gt; &lt;strong&gt;Dit Anti Bla...</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>Broomer</td>\n",
       "      <td>Donker</td>\n",
       "      <td>Kunststof</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578152</td>\n",
       "      <td>0.736169</td>\n",
       "      <td>0.602943</td>\n",
       "      <td>-0.225293</td>\n",
       "      <td>0.481169</td>\n",
       "      <td>-0.094827</td>\n",
       "      <td>0.243840</td>\n",
       "      <td>0.564650</td>\n",
       "      <td>0.143625</td>\n",
       "      <td>0.162856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>Y</td>\n",
       "      <td>Cyclones Hemp Cones Red Alert (24pcs/display) strawberry Blunt wraps  Vloei+wooden filter pre rolled</td>\n",
       "      <td>&lt;br /&gt;&lt;p&gt;  &lt;br /&gt;  &lt;/p&gt;&lt;br /&gt;&lt;p&gt;  &lt;br /&gt;  &lt;/p&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;  &lt;br /&gt;  &lt;/p&gt;</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>Cyclones</td>\n",
       "      <td>red</td>\n",
       "      <td>Hennep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677930</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>-0.391050</td>\n",
       "      <td>0.065601</td>\n",
       "      <td>0.263135</td>\n",
       "      <td>-0.343924</td>\n",
       "      <td>0.265229</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>-0.490359</td>\n",
       "      <td>1.257420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>N</td>\n",
       "      <td>Handroller Shag Apparaat – Sigarettenrolmachine Voor Sigaretten 8 cm – Shag Handroller – Random Kleur</td>\n",
       "      <td>Deze sigarettenroller voor 8 cm maat sigaret te maken. Het is gemaakt van plastic.&lt;br /&gt;Maak nu gemakkelijk en snel je sigaret met deze shag handroller.&lt;br /&gt;&lt;br /&gt;Het product wordt assorti geleverd.</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>Merkloos / Sans marque</td>\n",
       "      <td>Random</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284479</td>\n",
       "      <td>0.687781</td>\n",
       "      <td>0.238854</td>\n",
       "      <td>-0.047459</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>-0.061973</td>\n",
       "      <td>0.336674</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>1.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>N</td>\n",
       "      <td>Anti-blafband – Blafband – Stroomband -  Electric halsband - 7 niveaus - 3,5 tot 55 kg</td>\n",
       "      <td>Deze anti blafband stopt overmatig blaffen d.m.v. statische correctie in 7 verschillende niveaus. De anti blafband werk door middel van het opvangen van geluid en maakt hierbij gebruik van een microfoon om de blaf van uw hond op te sporen en te herkennen. Reageert op blaffen, janken en huilen&lt;br /&gt;Deze band zend eerst twee keer een waarschuwingstoon uit, als de hond binnen 30 seconden weer blaft volgt na de waarschuwingstoon een korte statische correctie. Blaft de hond door, wordt de intensiteit van de statische correctie verhoogt. De intensiteit van de statische correctie bedraagt 7 versc...</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>Merkloos / Sans marque</td>\n",
       "      <td>Zwart</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502338</td>\n",
       "      <td>0.646148</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.596833</td>\n",
       "      <td>-0.123715</td>\n",
       "      <td>0.628358</td>\n",
       "      <td>0.349240</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>1.134727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2968 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unwanted  \\\n",
       "0           Y   \n",
       "1           N   \n",
       "2           Y   \n",
       "3           N   \n",
       "4           Y   \n",
       "...       ...   \n",
       "2963        N   \n",
       "2964        N   \n",
       "2965        Y   \n",
       "2966        N   \n",
       "2967        N   \n",
       "\n",
       "                                                                                                                                        ProductTitleNL  \\\n",
       "0                                                                                                                                   Luxe Ginder- Zwart   \n",
       "1                                                                                                                   Jacob Hooy Valeriaanwortel gemalen   \n",
       "2                                                                                                                           SOG Bladelight Fixed Blade   \n",
       "3                                                          Nedis CCBW39300WT20 Data- En Oplaadkabel Apple Lightning 8-pins Male - Usb A Male 2,0 M Wit   \n",
       "4                                                                                                                          Cold Steel Two Handed Latin   \n",
       "...                                                                                                                                                ...   \n",
       "2963                                                                                                 Gift House international Pocket Multi Tool Zakmes   \n",
       "2964  Anti Blaf Apparaat  – Honden - Blaf Afstotend  – Veilig En Stopt Agressie & Blaffen -  Anti Blaffen - Diervriendelijk Anti Blaf Apparaat - Bruin   \n",
       "2965                                              Cyclones Hemp Cones Red Alert (24pcs/display) strawberry Blunt wraps  Vloei+wooden filter pre rolled   \n",
       "2966                                             Handroller Shag Apparaat – Sigarettenrolmachine Voor Sigaretten 8 cm – Shag Handroller – Random Kleur   \n",
       "2967                                                            Anti-blafband – Blafband – Stroomband -  Electric halsband - 7 niveaus - 3,5 tot 55 kg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ProductDescriptionNL  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    4-delig grinder (51mm diameter).\\nDeze grinder heeft glazen zij kanten zo dat je de kief voorraad kan zien groeien .\\nZwart/Zilver/Rood.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Jacob Hooy Valeriaanwortel gemalen   \n",
       "2                                                                                                                                       <p> SOG Bladelight Folder Uniek zakmes met verlichting!<br />6 felle LED lampjes verlichten het snijvlak of zijn gewoon handig als zaklamp.<br />Compleet met AAA batterij en etui. </p> KleurZwart met grijsHardheid57RcTotale lengte23.5 cmLengte lemmet11.5 cmModel lemmetClip PointLengte handgreep11.3 cmMateriaal handgreepGlass-Reinforced NylonStaalsoort8Cr13MoVAantal batterijen1Soort batterijenAA AlkalineBrandduur lamp2 uurSoort lampLEDLichtopbrengst30 lumenEtuiNylon   \n",
       "3                                                                              Kabel om een iPhone, iPad of iPod te verbinden met een PC om data te verzenden en te laden.<br /><ul><li>AWG-waarde: 30 / 22</li><li>Conductormateriaal: Koper</li><li>Connectie A: Apple Lightning</li><li>Connectie B: USB A Male</li><li>Connectordesign - kant A: Recht</li><li>Connectordesign - Kant B: Recht</li><li>Diameter: 3.1 mm</li><li>Kabelontwerp: Rond</li><li>Kleur: Wit</li><li>Lengte: 2.00 m</li><li>Materiaal buitenkant: PVC</li><li>Type connectorplating: Nikkel</li><li>Type kabel: Apple Lightning 8-Pins</li></ul>   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                      <p> Two handed Latin Machete.<br />dubbelhandig te gebruiken voor het zwaardere kapwerk. </p> KleurZwart Hardheid57Rc Totale lengte74.5 cm Model lemmetTanto Point Materiaal handgreepKunststof StaalsoortNiet roestvrij-Carbons Staal   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "2963  Met de IGGI Pocket Multi Tool op zak heb je altijd je gereedschap bij de hand! Deze Pocket Multi Tool heeft de afmetingen van een creditcard, dus perfect mee te nemen in je portefeuille en heeft 10 verschillende functies: een blikopener, snijrand, schroevendraaier, liniaal (5 cm), flesopener, 2-positie en 4-positie sleutel (voor verschillende maten van moeren en bouten), vlinder schroefsleutel, zaag en hulpsleutel. De Multi Tool is gemaakt van RVS en wordt geleverd met een bijbehorend plastic beschermhoesje.<br />Geweldig handig om bij je te hebben tijdens kamperen, vissen, fietsen of ande...   \n",
       "2964  <h3><strong>Broomer Anti Blaf Apparaat tegen irritant geblaf</strong></h3><p> Altijd al op zoek geweest naar een diervriendelijke methode om je hond te trainen en het irritante blaffen en ongewenst gedrag af te leren? Dan ben je bij Broomer aan het juiste adres! Met dit anti blaf apparaat voorkom je problemen met de buren. Het geblaf van jouw hond zal worden beperkt door de ultrasone frequentie. Met dit hoogwaardige ultrasoon geluid van dit anti-blaf apparaat stopt jouw hond met blaffen. Dit anti-blaf apparaat van Broomer is veilig en stopt agressie en blaffen. </p><p> <strong>Dit Anti Bla...   \n",
       "2965                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <br /><p>  <br />  </p><br /><p>  <br />  </p><br /><ul><li><br /></li><li><br /></li><li><br /></li><li><br /></li></ul><p>  <br />  </p>   \n",
       "2966                                                                                                                                                                                                                                                                                                                                                                                                                  Deze sigarettenroller voor 8 cm maat sigaret te maken. Het is gemaakt van plastic.<br />Maak nu gemakkelijk en snel je sigaret met deze shag handroller.<br /><br />Het product wordt assorti geleverd.   \n",
       "2967  Deze anti blafband stopt overmatig blaffen d.m.v. statische correctie in 7 verschillende niveaus. De anti blafband werk door middel van het opvangen van geluid en maakt hierbij gebruik van een microfoon om de blaf van uw hond op te sporen en te herkennen. Reageert op blaffen, janken en huilen<br />Deze band zend eerst twee keer een waarschuwingstoon uit, als de hond binnen 30 seconden weer blaft volgt na de waarschuwingstoon een korte statische correctie. Blaft de hond door, wordt de intensiteit van de statische correctie verhoogt. De intensiteit van de statische correctie bedraagt 7 versc...   \n",
       "\n",
       "                                                                        BrickName  \\\n",
       "0                                                                 Rookaccessoires   \n",
       "1                                                Keuken Snij-/Rasp-/Haktoestellen   \n",
       "2                                                   Hobbymessen (Niet-elektrisch)   \n",
       "3                                                                        Opladers   \n",
       "4                                                   Hobbymessen (Niet-elektrisch)   \n",
       "...                                                                           ...   \n",
       "2963                                                Hobbymessen (Niet-elektrisch)   \n",
       "2964  Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "2965                                                              Rookaccessoires   \n",
       "2966                                                              Rookaccessoires   \n",
       "2967  Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "\n",
       "                       ChunkName                 BrandName       Colour  \\\n",
       "0     Accessoire voor sigaretten              DeSmokerShop        Zwart   \n",
       "1                    Keukenmolen                Jacob Hooy          Wit   \n",
       "2                         Zakmes                       SOG          NaN   \n",
       "3                Batterijoplader                     Nedis          Wit   \n",
       "4                         Zakmes                Cold Steel          NaN   \n",
       "...                          ...                       ...          ...   \n",
       "2963                      Zakmes  Gift House International  Multicolour   \n",
       "2964          Opvoedingshalsband                   Broomer       Donker   \n",
       "2965  Accessoire voor sigaretten                  Cyclones          red   \n",
       "2966  Accessoire voor sigaretten    Merkloos / Sans marque       Random   \n",
       "2967          Opvoedingshalsband    Merkloos / Sans marque        Zwart   \n",
       "\n",
       "       Material  NumberOfProductsInPackage  PackageHeight  ...  text_758  \\\n",
       "0        Metaal                        NaN            3.2  ...  0.154095   \n",
       "1        Katoen                        NaN            NaN  ...  0.341660   \n",
       "2           NaN                        NaN            NaN  ...  0.571482   \n",
       "3           NaN                        1.0            NaN  ...  0.575893   \n",
       "4           NaN                        NaN            NaN  ...  0.229359   \n",
       "...         ...                        ...            ...  ...       ...   \n",
       "2963        NaN                        NaN            4.0  ...  0.483081   \n",
       "2964  Kunststof                        NaN           50.0  ...  0.578152   \n",
       "2965     Hennep                        NaN           12.0  ...  0.677930   \n",
       "2966    Plastic                        NaN            0.0  ...  0.284479   \n",
       "2967    Plastic                        NaN            0.0  ...  0.502338   \n",
       "\n",
       "      text_759  text_760  text_761  text_762  text_763  text_764  text_765  \\\n",
       "0     0.527087 -0.065295 -0.057718  0.412198  0.006492  0.741614  0.330917   \n",
       "1     0.481505  0.279541 -0.391992 -0.713672  0.319069 -0.177490 -0.340997   \n",
       "2     0.515193  0.046478 -0.109512  0.473507 -0.113991  0.682185  0.303920   \n",
       "3     0.578776  0.754166 -0.215556  0.388041 -0.159984  0.028604  0.487187   \n",
       "4     0.519005 -0.085757 -0.079637  0.451944  0.093129  0.480540  0.333043   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2963  0.617548  0.778052 -0.272631  0.148481 -0.013954  0.008333  0.754632   \n",
       "2964  0.736169  0.602943 -0.225293  0.481169 -0.094827  0.243840  0.564650   \n",
       "2965  0.113892 -0.391050  0.065601  0.263135 -0.343924  0.265229  0.016922   \n",
       "2966  0.687781  0.238854 -0.047459  0.708569 -0.061973  0.336674  0.431229   \n",
       "2967  0.646148  0.003367  0.020502  0.596833 -0.123715  0.628358  0.349240   \n",
       "\n",
       "      text_766  text_767  \n",
       "0    -0.036481  1.079142  \n",
       "1     0.043457 -0.326661  \n",
       "2     0.217693  1.066162  \n",
       "3     0.043950  0.315264  \n",
       "4     0.283477  1.007419  \n",
       "...        ...       ...  \n",
       "2963  0.024003 -0.286155  \n",
       "2964  0.143625  0.162856  \n",
       "2965 -0.490359  1.257420  \n",
       "2966  0.001302  1.004086  \n",
       "2967  0.037226  1.134727  \n",
       "\n",
       "[2968 rows x 797 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('./data/featurized/V2/train.csv')\n",
    "valid_data = TabularDataset('./data/featurized/V2/valid.csv')\n",
    "test_data = TabularDataset('./data/featurized/V2/test.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sitting-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop image/text probas\n",
    "to_drop = [\"img_proba_for_N\", \"img_proba_for_Y\", \"text_proba_for_N\", \"text_proba_for_Y\"]\n",
    "test_data.drop(to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "removed-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unwanted</th>\n",
       "      <th>ProductTitleNL</th>\n",
       "      <th>ProductDescriptionNL</th>\n",
       "      <th>BrickName</th>\n",
       "      <th>ChunkName</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Material</th>\n",
       "      <th>NumberOfProductsInPackage</th>\n",
       "      <th>PackageHeight</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>Luxe Ginder- Zwart</td>\n",
       "      <td>4-delig grinder (51mm diameter).\\nDeze grinder heeft glazen zij kanten zo dat je de kief voorraad kan zien groeien .\\nZwart/Zilver/Rood.</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>DeSmokerShop</td>\n",
       "      <td>Zwart</td>\n",
       "      <td>Metaal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154095</td>\n",
       "      <td>0.527087</td>\n",
       "      <td>-0.065295</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.412198</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.741614</td>\n",
       "      <td>0.330917</td>\n",
       "      <td>-0.036481</td>\n",
       "      <td>1.079142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Jacob Hooy Valeriaanwortel gemalen</td>\n",
       "      <td>Jacob Hooy Valeriaanwortel gemalen</td>\n",
       "      <td>Keuken Snij-/Rasp-/Haktoestellen</td>\n",
       "      <td>Keukenmolen</td>\n",
       "      <td>Jacob Hooy</td>\n",
       "      <td>Wit</td>\n",
       "      <td>Katoen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341660</td>\n",
       "      <td>0.481505</td>\n",
       "      <td>0.279541</td>\n",
       "      <td>-0.391992</td>\n",
       "      <td>-0.713672</td>\n",
       "      <td>0.319069</td>\n",
       "      <td>-0.177490</td>\n",
       "      <td>-0.340997</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>-0.326661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>SOG Bladelight Fixed Blade</td>\n",
       "      <td>&lt;p&gt; SOG Bladelight Folder Uniek zakmes met verlichting!&lt;br /&gt;6 felle LED lampjes verlichten het snijvlak of zijn gewoon handig als zaklamp.&lt;br /&gt;Compleet met AAA batterij en etui. &lt;/p&gt; KleurZwart met grijsHardheid57RcTotale lengte23.5 cmLengte lemmet11.5 cmModel lemmetClip PointLengte handgreep11.3 cmMateriaal handgreepGlass-Reinforced NylonStaalsoort8Cr13MoVAantal batterijen1Soort batterijenAA AlkalineBrandduur lamp2 uurSoort lampLEDLichtopbrengst30 lumenEtuiNylon</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>SOG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571482</td>\n",
       "      <td>0.515193</td>\n",
       "      <td>0.046478</td>\n",
       "      <td>-0.109512</td>\n",
       "      <td>0.473507</td>\n",
       "      <td>-0.113991</td>\n",
       "      <td>0.682185</td>\n",
       "      <td>0.303920</td>\n",
       "      <td>0.217693</td>\n",
       "      <td>1.066162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>Nedis CCBW39300WT20 Data- En Oplaadkabel Apple Lightning 8-pins Male - Usb A Male 2,0 M Wit</td>\n",
       "      <td>Kabel om een iPhone, iPad of iPod te verbinden met een PC om data te verzenden en te laden.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;AWG-waarde: 30 / 22&lt;/li&gt;&lt;li&gt;Conductormateriaal: Koper&lt;/li&gt;&lt;li&gt;Connectie A: Apple Lightning&lt;/li&gt;&lt;li&gt;Connectie B: USB A Male&lt;/li&gt;&lt;li&gt;Connectordesign - kant A: Recht&lt;/li&gt;&lt;li&gt;Connectordesign - Kant B: Recht&lt;/li&gt;&lt;li&gt;Diameter: 3.1 mm&lt;/li&gt;&lt;li&gt;Kabelontwerp: Rond&lt;/li&gt;&lt;li&gt;Kleur: Wit&lt;/li&gt;&lt;li&gt;Lengte: 2.00 m&lt;/li&gt;&lt;li&gt;Materiaal buitenkant: PVC&lt;/li&gt;&lt;li&gt;Type connectorplating: Nikkel&lt;/li&gt;&lt;li&gt;Type kabel: Apple Lightning 8-Pins&lt;/li&gt;&lt;/ul&gt;</td>\n",
       "      <td>Opladers</td>\n",
       "      <td>Batterijoplader</td>\n",
       "      <td>Nedis</td>\n",
       "      <td>Wit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575893</td>\n",
       "      <td>0.578776</td>\n",
       "      <td>0.754166</td>\n",
       "      <td>-0.215556</td>\n",
       "      <td>0.388041</td>\n",
       "      <td>-0.159984</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.487187</td>\n",
       "      <td>0.043950</td>\n",
       "      <td>0.315264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>Cold Steel Two Handed Latin</td>\n",
       "      <td>&lt;p&gt; Two handed Latin Machete.&lt;br /&gt;dubbelhandig te gebruiken voor het zwaardere kapwerk. &lt;/p&gt; KleurZwart Hardheid57Rc Totale lengte74.5 cm Model lemmetTanto Point Materiaal handgreepKunststof StaalsoortNiet roestvrij-Carbons Staal</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Cold Steel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229359</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>-0.085757</td>\n",
       "      <td>-0.079637</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>0.480540</td>\n",
       "      <td>0.333043</td>\n",
       "      <td>0.283477</td>\n",
       "      <td>1.007419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>N</td>\n",
       "      <td>Gift House international Pocket Multi Tool Zakmes</td>\n",
       "      <td>Met de IGGI Pocket Multi Tool op zak heb je altijd je gereedschap bij de hand! Deze Pocket Multi Tool heeft de afmetingen van een creditcard, dus perfect mee te nemen in je portefeuille en heeft 10 verschillende functies: een blikopener, snijrand, schroevendraaier, liniaal (5 cm), flesopener, 2-positie en 4-positie sleutel (voor verschillende maten van moeren en bouten), vlinder schroefsleutel, zaag en hulpsleutel. De Multi Tool is gemaakt van RVS en wordt geleverd met een bijbehorend plastic beschermhoesje.&lt;br /&gt;Geweldig handig om bij je te hebben tijdens kamperen, vissen, fietsen of ande...</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Gift House International</td>\n",
       "      <td>Multicolour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483081</td>\n",
       "      <td>0.617548</td>\n",
       "      <td>0.778052</td>\n",
       "      <td>-0.272631</td>\n",
       "      <td>0.148481</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.754632</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>-0.286155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>N</td>\n",
       "      <td>Anti Blaf Apparaat  – Honden - Blaf Afstotend  – Veilig En Stopt Agressie &amp; Blaffen -  Anti Blaffen - Diervriendelijk Anti Blaf Apparaat - Bruin</td>\n",
       "      <td>&lt;h3&gt;&lt;strong&gt;Broomer Anti Blaf Apparaat tegen irritant geblaf&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt; Altijd al op zoek geweest naar een diervriendelijke methode om je hond te trainen en het irritante blaffen en ongewenst gedrag af te leren? Dan ben je bij Broomer aan het juiste adres! Met dit anti blaf apparaat voorkom je problemen met de buren. Het geblaf van jouw hond zal worden beperkt door de ultrasone frequentie. Met dit hoogwaardige ultrasoon geluid van dit anti-blaf apparaat stopt jouw hond met blaffen. Dit anti-blaf apparaat van Broomer is veilig en stopt agressie en blaffen. &lt;/p&gt;&lt;p&gt; &lt;strong&gt;Dit Anti Bla...</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>Broomer</td>\n",
       "      <td>Donker</td>\n",
       "      <td>Kunststof</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578152</td>\n",
       "      <td>0.736169</td>\n",
       "      <td>0.602943</td>\n",
       "      <td>-0.225293</td>\n",
       "      <td>0.481169</td>\n",
       "      <td>-0.094827</td>\n",
       "      <td>0.243840</td>\n",
       "      <td>0.564650</td>\n",
       "      <td>0.143625</td>\n",
       "      <td>0.162856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>Y</td>\n",
       "      <td>Cyclones Hemp Cones Red Alert (24pcs/display) strawberry Blunt wraps  Vloei+wooden filter pre rolled</td>\n",
       "      <td>&lt;br /&gt;&lt;p&gt;  &lt;br /&gt;  &lt;/p&gt;&lt;br /&gt;&lt;p&gt;  &lt;br /&gt;  &lt;/p&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;br /&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;  &lt;br /&gt;  &lt;/p&gt;</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>Cyclones</td>\n",
       "      <td>red</td>\n",
       "      <td>Hennep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677930</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>-0.391050</td>\n",
       "      <td>0.065601</td>\n",
       "      <td>0.263135</td>\n",
       "      <td>-0.343924</td>\n",
       "      <td>0.265229</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>-0.490359</td>\n",
       "      <td>1.257420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>N</td>\n",
       "      <td>Handroller Shag Apparaat – Sigarettenrolmachine Voor Sigaretten 8 cm – Shag Handroller – Random Kleur</td>\n",
       "      <td>Deze sigarettenroller voor 8 cm maat sigaret te maken. Het is gemaakt van plastic.&lt;br /&gt;Maak nu gemakkelijk en snel je sigaret met deze shag handroller.&lt;br /&gt;&lt;br /&gt;Het product wordt assorti geleverd.</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>Merkloos / Sans marque</td>\n",
       "      <td>Random</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284479</td>\n",
       "      <td>0.687781</td>\n",
       "      <td>0.238854</td>\n",
       "      <td>-0.047459</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>-0.061973</td>\n",
       "      <td>0.336674</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>1.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>N</td>\n",
       "      <td>Anti-blafband – Blafband – Stroomband -  Electric halsband - 7 niveaus - 3,5 tot 55 kg</td>\n",
       "      <td>Deze anti blafband stopt overmatig blaffen d.m.v. statische correctie in 7 verschillende niveaus. De anti blafband werk door middel van het opvangen van geluid en maakt hierbij gebruik van een microfoon om de blaf van uw hond op te sporen en te herkennen. Reageert op blaffen, janken en huilen&lt;br /&gt;Deze band zend eerst twee keer een waarschuwingstoon uit, als de hond binnen 30 seconden weer blaft volgt na de waarschuwingstoon een korte statische correctie. Blaft de hond door, wordt de intensiteit van de statische correctie verhoogt. De intensiteit van de statische correctie bedraagt 7 versc...</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>Merkloos / Sans marque</td>\n",
       "      <td>Zwart</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502338</td>\n",
       "      <td>0.646148</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>0.596833</td>\n",
       "      <td>-0.123715</td>\n",
       "      <td>0.628358</td>\n",
       "      <td>0.349240</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>1.134727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2968 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unwanted  \\\n",
       "0           Y   \n",
       "1           N   \n",
       "2           Y   \n",
       "3           N   \n",
       "4           Y   \n",
       "...       ...   \n",
       "2963        N   \n",
       "2964        N   \n",
       "2965        Y   \n",
       "2966        N   \n",
       "2967        N   \n",
       "\n",
       "                                                                                                                                        ProductTitleNL  \\\n",
       "0                                                                                                                                   Luxe Ginder- Zwart   \n",
       "1                                                                                                                   Jacob Hooy Valeriaanwortel gemalen   \n",
       "2                                                                                                                           SOG Bladelight Fixed Blade   \n",
       "3                                                          Nedis CCBW39300WT20 Data- En Oplaadkabel Apple Lightning 8-pins Male - Usb A Male 2,0 M Wit   \n",
       "4                                                                                                                          Cold Steel Two Handed Latin   \n",
       "...                                                                                                                                                ...   \n",
       "2963                                                                                                 Gift House international Pocket Multi Tool Zakmes   \n",
       "2964  Anti Blaf Apparaat  – Honden - Blaf Afstotend  – Veilig En Stopt Agressie & Blaffen -  Anti Blaffen - Diervriendelijk Anti Blaf Apparaat - Bruin   \n",
       "2965                                              Cyclones Hemp Cones Red Alert (24pcs/display) strawberry Blunt wraps  Vloei+wooden filter pre rolled   \n",
       "2966                                             Handroller Shag Apparaat – Sigarettenrolmachine Voor Sigaretten 8 cm – Shag Handroller – Random Kleur   \n",
       "2967                                                            Anti-blafband – Blafband – Stroomband -  Electric halsband - 7 niveaus - 3,5 tot 55 kg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ProductDescriptionNL  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    4-delig grinder (51mm diameter).\\nDeze grinder heeft glazen zij kanten zo dat je de kief voorraad kan zien groeien .\\nZwart/Zilver/Rood.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Jacob Hooy Valeriaanwortel gemalen   \n",
       "2                                                                                                                                       <p> SOG Bladelight Folder Uniek zakmes met verlichting!<br />6 felle LED lampjes verlichten het snijvlak of zijn gewoon handig als zaklamp.<br />Compleet met AAA batterij en etui. </p> KleurZwart met grijsHardheid57RcTotale lengte23.5 cmLengte lemmet11.5 cmModel lemmetClip PointLengte handgreep11.3 cmMateriaal handgreepGlass-Reinforced NylonStaalsoort8Cr13MoVAantal batterijen1Soort batterijenAA AlkalineBrandduur lamp2 uurSoort lampLEDLichtopbrengst30 lumenEtuiNylon   \n",
       "3                                                                              Kabel om een iPhone, iPad of iPod te verbinden met een PC om data te verzenden en te laden.<br /><ul><li>AWG-waarde: 30 / 22</li><li>Conductormateriaal: Koper</li><li>Connectie A: Apple Lightning</li><li>Connectie B: USB A Male</li><li>Connectordesign - kant A: Recht</li><li>Connectordesign - Kant B: Recht</li><li>Diameter: 3.1 mm</li><li>Kabelontwerp: Rond</li><li>Kleur: Wit</li><li>Lengte: 2.00 m</li><li>Materiaal buitenkant: PVC</li><li>Type connectorplating: Nikkel</li><li>Type kabel: Apple Lightning 8-Pins</li></ul>   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                      <p> Two handed Latin Machete.<br />dubbelhandig te gebruiken voor het zwaardere kapwerk. </p> KleurZwart Hardheid57Rc Totale lengte74.5 cm Model lemmetTanto Point Materiaal handgreepKunststof StaalsoortNiet roestvrij-Carbons Staal   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "2963  Met de IGGI Pocket Multi Tool op zak heb je altijd je gereedschap bij de hand! Deze Pocket Multi Tool heeft de afmetingen van een creditcard, dus perfect mee te nemen in je portefeuille en heeft 10 verschillende functies: een blikopener, snijrand, schroevendraaier, liniaal (5 cm), flesopener, 2-positie en 4-positie sleutel (voor verschillende maten van moeren en bouten), vlinder schroefsleutel, zaag en hulpsleutel. De Multi Tool is gemaakt van RVS en wordt geleverd met een bijbehorend plastic beschermhoesje.<br />Geweldig handig om bij je te hebben tijdens kamperen, vissen, fietsen of ande...   \n",
       "2964  <h3><strong>Broomer Anti Blaf Apparaat tegen irritant geblaf</strong></h3><p> Altijd al op zoek geweest naar een diervriendelijke methode om je hond te trainen en het irritante blaffen en ongewenst gedrag af te leren? Dan ben je bij Broomer aan het juiste adres! Met dit anti blaf apparaat voorkom je problemen met de buren. Het geblaf van jouw hond zal worden beperkt door de ultrasone frequentie. Met dit hoogwaardige ultrasoon geluid van dit anti-blaf apparaat stopt jouw hond met blaffen. Dit anti-blaf apparaat van Broomer is veilig en stopt agressie en blaffen. </p><p> <strong>Dit Anti Bla...   \n",
       "2965                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <br /><p>  <br />  </p><br /><p>  <br />  </p><br /><ul><li><br /></li><li><br /></li><li><br /></li><li><br /></li></ul><p>  <br />  </p>   \n",
       "2966                                                                                                                                                                                                                                                                                                                                                                                                                  Deze sigarettenroller voor 8 cm maat sigaret te maken. Het is gemaakt van plastic.<br />Maak nu gemakkelijk en snel je sigaret met deze shag handroller.<br /><br />Het product wordt assorti geleverd.   \n",
       "2967  Deze anti blafband stopt overmatig blaffen d.m.v. statische correctie in 7 verschillende niveaus. De anti blafband werk door middel van het opvangen van geluid en maakt hierbij gebruik van een microfoon om de blaf van uw hond op te sporen en te herkennen. Reageert op blaffen, janken en huilen<br />Deze band zend eerst twee keer een waarschuwingstoon uit, als de hond binnen 30 seconden weer blaft volgt na de waarschuwingstoon een korte statische correctie. Blaft de hond door, wordt de intensiteit van de statische correctie verhoogt. De intensiteit van de statische correctie bedraagt 7 versc...   \n",
       "\n",
       "                                                                        BrickName  \\\n",
       "0                                                                 Rookaccessoires   \n",
       "1                                                Keuken Snij-/Rasp-/Haktoestellen   \n",
       "2                                                   Hobbymessen (Niet-elektrisch)   \n",
       "3                                                                        Opladers   \n",
       "4                                                   Hobbymessen (Niet-elektrisch)   \n",
       "...                                                                           ...   \n",
       "2963                                                Hobbymessen (Niet-elektrisch)   \n",
       "2964  Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "2965                                                              Rookaccessoires   \n",
       "2966                                                              Rookaccessoires   \n",
       "2967  Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "\n",
       "                       ChunkName                 BrandName       Colour  \\\n",
       "0     Accessoire voor sigaretten              DeSmokerShop        Zwart   \n",
       "1                    Keukenmolen                Jacob Hooy          Wit   \n",
       "2                         Zakmes                       SOG          NaN   \n",
       "3                Batterijoplader                     Nedis          Wit   \n",
       "4                         Zakmes                Cold Steel          NaN   \n",
       "...                          ...                       ...          ...   \n",
       "2963                      Zakmes  Gift House International  Multicolour   \n",
       "2964          Opvoedingshalsband                   Broomer       Donker   \n",
       "2965  Accessoire voor sigaretten                  Cyclones          red   \n",
       "2966  Accessoire voor sigaretten    Merkloos / Sans marque       Random   \n",
       "2967          Opvoedingshalsband    Merkloos / Sans marque        Zwart   \n",
       "\n",
       "       Material  NumberOfProductsInPackage  PackageHeight  ...       758  \\\n",
       "0        Metaal                        NaN            3.2  ...  0.154095   \n",
       "1        Katoen                        NaN            NaN  ...  0.341660   \n",
       "2           NaN                        NaN            NaN  ...  0.571482   \n",
       "3           NaN                        1.0            NaN  ...  0.575893   \n",
       "4           NaN                        NaN            NaN  ...  0.229359   \n",
       "...         ...                        ...            ...  ...       ...   \n",
       "2963        NaN                        NaN            4.0  ...  0.483081   \n",
       "2964  Kunststof                        NaN           50.0  ...  0.578152   \n",
       "2965     Hennep                        NaN           12.0  ...  0.677930   \n",
       "2966    Plastic                        NaN            0.0  ...  0.284479   \n",
       "2967    Plastic                        NaN            0.0  ...  0.502338   \n",
       "\n",
       "           759       760       761       762       763       764       765  \\\n",
       "0     0.527087 -0.065295 -0.057718  0.412198  0.006492  0.741614  0.330917   \n",
       "1     0.481505  0.279541 -0.391992 -0.713672  0.319069 -0.177490 -0.340997   \n",
       "2     0.515193  0.046478 -0.109512  0.473507 -0.113991  0.682185  0.303920   \n",
       "3     0.578776  0.754166 -0.215556  0.388041 -0.159984  0.028604  0.487187   \n",
       "4     0.519005 -0.085757 -0.079637  0.451944  0.093129  0.480540  0.333043   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2963  0.617548  0.778052 -0.272631  0.148481 -0.013954  0.008333  0.754632   \n",
       "2964  0.736169  0.602943 -0.225293  0.481169 -0.094827  0.243840  0.564650   \n",
       "2965  0.113892 -0.391050  0.065601  0.263135 -0.343924  0.265229  0.016922   \n",
       "2966  0.687781  0.238854 -0.047459  0.708569 -0.061973  0.336674  0.431229   \n",
       "2967  0.646148  0.003367  0.020502  0.596833 -0.123715  0.628358  0.349240   \n",
       "\n",
       "           766       767  \n",
       "0    -0.036481  1.079142  \n",
       "1     0.043457 -0.326661  \n",
       "2     0.217693  1.066162  \n",
       "3     0.043950  0.315264  \n",
       "4     0.283477  1.007419  \n",
       "...        ...       ...  \n",
       "2963  0.024003 -0.286155  \n",
       "2964  0.143625  0.162856  \n",
       "2965 -0.490359  1.257420  \n",
       "2966  0.001302  1.004086  \n",
       "2967  0.037226  1.134727  \n",
       "\n",
       "[2968 rows x 797 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_text_with_embeddings = TabularDataset('./data/enrichedWithTextProba/train_with_embeddings.csv')\n",
    "valid_data_text_with_embeddings = TabularDataset('./data/enrichedWithTextProba/valid_with_embeddings.csv')\n",
    "test_data_text_with_embeddings = TabularDataset('./data/enrichedWithTextProba/test_with_embeddings.csv')\n",
    "train_data_text_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "stopped-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductTitleNL</th>\n",
       "      <th>ProductDescriptionNL</th>\n",
       "      <th>BrickName</th>\n",
       "      <th>ChunkName</th>\n",
       "      <th>BrandName</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Material</th>\n",
       "      <th>NumberOfProductsInPackage</th>\n",
       "      <th>PackageHeight</th>\n",
       "      <th>PackageHeightUnit</th>\n",
       "      <th>...</th>\n",
       "      <th>text_758</th>\n",
       "      <th>text_759</th>\n",
       "      <th>text_760</th>\n",
       "      <th>text_761</th>\n",
       "      <th>text_762</th>\n",
       "      <th>text_763</th>\n",
       "      <th>text_764</th>\n",
       "      <th>text_765</th>\n",
       "      <th>text_766</th>\n",
       "      <th>text_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nobby correctieketting 10-45 x 3 cm - 1 st</td>\n",
       "      <td>De Nobby correctieketting is gemaakt met het oog op kwaliteit, duurzaamheid en draagcomfort. De ketting bestaat uit schakels.&lt;br /&gt;&lt;br /&gt;Doordat de halsband kleiner wordt wanneer je hond trekt corrigeert hij zichzelf zodat het onplezierige gevoel van een strakke halsband verdwijnt. &lt;br /&gt;&lt;br /&gt;In verschillende maten verkrijgbaar.&lt;br /&gt;- Afmetingen: 3 MM X 45 CM&lt;br /&gt;&lt;br /&gt;- Geleverd per: 1 ST</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>Nobby</td>\n",
       "      <td>Grijs</td>\n",
       "      <td>Metaal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507512</td>\n",
       "      <td>0.735776</td>\n",
       "      <td>0.798402</td>\n",
       "      <td>-0.225944</td>\n",
       "      <td>0.348368</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.281298</td>\n",
       "      <td>0.604051</td>\n",
       "      <td>0.204834</td>\n",
       "      <td>0.107701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bore Snake Kaliber 410</td>\n",
       "      <td>&lt;p&gt; Poets de loop van u wapen in 10 seconden met een equivalent van 160 poetsdoekjes. In een enkele poetsbeurt!&lt;br /&gt; &lt;/p&gt;&lt;p&gt; &lt;br /&gt; &lt;/p&gt;&lt;h3&gt;Wat is een Bore Snake?&lt;/h3&gt;&lt;p&gt; De Bore Snake is een lange koord uit geweven katoen met aan de voorkant een gewicht uit messing. De Bore Snake bestaat uit 2 delen, een trekkoord om hem door de loop te krijgen en een poetsgedeelte. Het begin van de Bore Snake bestaat uit een grootte gepofte bal van katoen waar je wapen olie, wapen poets middel of iets anders op kan doen.  Verderop in de Bore Snake bevindt zich een borstel van met messing, gevolgd door e...</td>\n",
       "      <td>Buiten/Tuin Speelgoed</td>\n",
       "      <td>Schietspeelgoedaccessoires</td>\n",
       "      <td>Cobra Tactical Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100% polyester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188966</td>\n",
       "      <td>0.871161</td>\n",
       "      <td>-0.247050</td>\n",
       "      <td>-0.036275</td>\n",
       "      <td>0.358823</td>\n",
       "      <td>0.060928</td>\n",
       "      <td>0.537199</td>\n",
       "      <td>0.382411</td>\n",
       "      <td>0.213614</td>\n",
       "      <td>0.933042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Homey's Machete Fieldpal - Zwart Staal - Rubber - Glad Lemmet</td>\n",
       "      <td>What’s in a name?! Fieldpal is de maat waar je niet zonder kunt als je je in kampeer-/survivaltochten begeeft. Een kapmes waarmee je je een weg door de jungle baant, een kokosnoot openhakt of riet aan de waterkant kapt voor een perfecte visstek.&lt;br /&gt;&lt;br /&gt;De Fieldpal machete is uitermate geschikt voor de landbouw en dan vooral bij het kappen van (suiker)riet. Een onmisbaar werktuig dus!&lt;br /&gt;In tegenstelling tot vele andere machetes, waarvan het lemmet niet roestbestendig is, is het lemmet van Fieldpal van 420 roestvrij staal. Daarbij is het lemmet zwart voor een tactische look!&lt;br /&gt;Het ...</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>HOMEY’s TOOLS FOR LIFE</td>\n",
       "      <td>Zwart</td>\n",
       "      <td>Rubber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>unece.unit.MMT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340339</td>\n",
       "      <td>0.713510</td>\n",
       "      <td>0.043395</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.609852</td>\n",
       "      <td>0.122007</td>\n",
       "      <td>0.546514</td>\n",
       "      <td>0.567774</td>\n",
       "      <td>-0.065915</td>\n",
       "      <td>0.758254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petsafe Easy Walk Anti-Trek Rood</td>\n",
       "      <td>Het Easy Walk harnas is een comfortabel en gemakkelijk om te doen harnas die het lopen met uw huisdier plezierig maakt voor u beiden. De bevestiging voor de lijn geeft u de controle. Voor stress-vrije wandelingen.</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>PetSafe</td>\n",
       "      <td>Rood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409554</td>\n",
       "      <td>0.716285</td>\n",
       "      <td>0.739491</td>\n",
       "      <td>-0.395622</td>\n",
       "      <td>0.375344</td>\n",
       "      <td>0.133185</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.549106</td>\n",
       "      <td>0.210281</td>\n",
       "      <td>-0.268637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joker CR18 vaststaand mes</td>\n",
       "      <td>Een jachtmes van het Spaanse merk Joker met een mooi rood houten handvat.De Joker CR18 vaststaand mes is een jachtmes met een van lemmet van Vanadium Molybdeenstaal. Het handvat is gemaakt van een rood hout. Het mes wordt geleverd inclusief een bruine lederen schede waar het mes mooi in kan worden opgeborgen.&lt;br /&gt;Joker is een merk uit Spanje dat reeds bestaat sinds 1987. Zij staan bekend om de traditionele en handgemaakte producten met moderne technologieën. Voor de messen wordt kwaliteitsstaal gebruikt zoals 440, 1095 carbon staal en Sandvick staal. De handvatten worden afgewerkt met oli...</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Joker</td>\n",
       "      <td>Zilver met roodachtig hout</td>\n",
       "      <td>Hout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>unece.unit.CMT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242094</td>\n",
       "      <td>0.518071</td>\n",
       "      <td>-0.208649</td>\n",
       "      <td>0.047773</td>\n",
       "      <td>0.322289</td>\n",
       "      <td>0.064792</td>\n",
       "      <td>0.736442</td>\n",
       "      <td>0.377610</td>\n",
       "      <td>-0.072555</td>\n",
       "      <td>1.174717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>HGHLF Cloud Grinder Precision 2-delig (Zwart)</td>\n",
       "      <td>De HGHLF® Cloud Grinders zijn gefabriceerd uit de hoogste kwaliteit Aircraft Grade Aluminium.&lt;br /&gt;Ze zijn onverwoestbaar en gaan voor altijd mee.&lt;br /&gt;&lt;br /&gt;Uitgerust met de meest geavanceerde curved leeuwen tanden ben je gegarandeerd van de fijnste vermaling.&lt;br /&gt;Dankzij de neodynium magneet sluitingssysteem blijft je grinder ook gesloten wanneer je on the go bent!&lt;br /&gt;&lt;br /&gt;HGHLF is het nummer 1 merk op vlak van rol accessoires.&lt;br /&gt;HGHLF - First Class Rolling Gear</td>\n",
       "      <td>Keuken Snij-/Rasp-/Haktoestellen</td>\n",
       "      <td>Keukenmolen</td>\n",
       "      <td>HGHLF</td>\n",
       "      <td>Pitch Black</td>\n",
       "      <td>Aluminium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>unece.unit.MMT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331174</td>\n",
       "      <td>0.607316</td>\n",
       "      <td>-0.163724</td>\n",
       "      <td>-0.009131</td>\n",
       "      <td>0.510441</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.697754</td>\n",
       "      <td>0.285001</td>\n",
       "      <td>0.040795</td>\n",
       "      <td>1.127209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Gerber Bear Grylls Folding Sheath Zakmes</td>\n",
       "      <td>Gerber Bear Grylls Folding Sheath Zakmes is gemaakt voor mensen die een volwaardig mes willen, maar wel compact, inklapbaar en geschikt om op te bergen in een foedraal aan de riem.&lt;br /&gt;&lt;br /&gt;Kenmerken:&lt;br /&gt;• ½ gekarteld droppoint lemmet van RVS met een hoog koolstofgehalte - ideaal voor randscherpte en het snijden van touw&lt;br /&gt;• Duimsteun aan twee kanten - voor eenvoudig eenhandig openen&lt;br /&gt;• Ergonomische rubberen structuurhandgreep - maximaal comfort en minimaal wegglijden&lt;br /&gt;• Lock back - vergrendelt het lemmet stevig en zorgt voor maximale veiligheid bij inklappen&lt;br /&gt;• Nylon fo...</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Gerber</td>\n",
       "      <td>Oranje / zwart</td>\n",
       "      <td>Rubber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>unece.unit.MMT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706961</td>\n",
       "      <td>0.674504</td>\n",
       "      <td>0.147302</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>0.655224</td>\n",
       "      <td>-0.200165</td>\n",
       "      <td>0.675610</td>\n",
       "      <td>0.271636</td>\n",
       "      <td>0.171715</td>\n",
       "      <td>1.064215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>vidaXL Trainingsband - omtrek tot 70 cm - 7 standen - spatwaterbestendig</td>\n",
       "      <td>&lt;p&gt;   Deze humane hondentrainhalsband geeft eerst een onschuldig waarschuwingsgeluid voor dat de halsband steeds zwaardere schokken geeft als de hond blijft blaffen. Hij schakelt door 7 correctieniveau's. Na 7 opeenvolgende schokken schakelt de halsband in een automatische beschermmodus van 1 minuut. Deze handige trainingshalsband heeft een aanpasbare gevoeligheid om te passen bij verschillende honden. Hij heeft een aanpasbare halsband die past tot nekomtrekken van 70 cm. Doordat de halsband gemaakt is van hoogwaardig ABS, is deze trainingshalsband spatwaterbestendig en gaat hij lang mee. ...</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>vidaXL</td>\n",
       "      <td>zwart</td>\n",
       "      <td>Kunststof</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301048</td>\n",
       "      <td>0.729011</td>\n",
       "      <td>-0.058431</td>\n",
       "      <td>-0.068579</td>\n",
       "      <td>0.364053</td>\n",
       "      <td>-0.063120</td>\n",
       "      <td>0.435569</td>\n",
       "      <td>0.421877</td>\n",
       "      <td>0.433908</td>\n",
       "      <td>0.849236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>ANTI BLAFBAND PRO MET STATISCHE CORRECTIE</td>\n",
       "      <td>Nieuwste high-tech band van het het alom geprezen merk Furline®, die zowel een vibratie al waarschuwing gebruikt, evenals een schokje om u te helpen bij de training van uw hond. Nu de doorontwikkelde Pro versie met verbeterde gevoeligheid, en oplaadbaar dus geen gedoe met batterijen!&lt;br /&gt;&lt;br /&gt;Deze kwaliteitsband heeft een garantie van 10 jaar!&lt;br /&gt;&lt;br /&gt;Deze halsband is een zeer effectief gedragsveranderings apparaat om te helpen trainen uw hond te blaffen overlast en slecht gedrag te stoppen. Als uw hond blaft, geeft de Furline Pro band een vibratie samen met een licht schokje. Het hoo...</td>\n",
       "      <td>Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)</td>\n",
       "      <td>Opvoedingshalsband</td>\n",
       "      <td>Furline Pro</td>\n",
       "      <td>zwart</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>unece.unit.MMT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532541</td>\n",
       "      <td>0.743138</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>-0.012161</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>-0.051846</td>\n",
       "      <td>0.510310</td>\n",
       "      <td>0.380803</td>\n",
       "      <td>0.012688</td>\n",
       "      <td>0.899228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>10 zwarte cones/holders/Tubes voor sigaretten - Joints - Te bewaren - Te beschermen</td>\n",
       "      <td>Niets zo ambetant als sigaretten of andere dingen die breken in uw zak tijdens het wandelen.&lt;br /&gt;Dat is vanaf nu verleden tijd met deze 10 cones.&lt;br /&gt;Speciaal in een zwarte kleur zodat de zon er niet kan doorkomen.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Indien u meer als 10 stuks wilt bestellen, heeft u recht op aanvraag van een offerte.&lt;br /&gt;Aarzel niet om ons te contacteren en wij beloven een mooie korting voor grotere hoeveelheden.&lt;br /&gt;Bij ECOSTAREGENT staan een snelle levering, kwaliteit, mooie verpakking en goede service centraal.</td>\n",
       "      <td>Rookaccessoires</td>\n",
       "      <td>Accessoire voor sigaretten</td>\n",
       "      <td>ECOSTARE</td>\n",
       "      <td>Zwart</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>unece.unit.MMT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644087</td>\n",
       "      <td>0.736305</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>-0.077947</td>\n",
       "      <td>0.702133</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.431552</td>\n",
       "      <td>0.591613</td>\n",
       "      <td>0.111937</td>\n",
       "      <td>0.617980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows × 796 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          ProductTitleNL  \\\n",
       "0                                             Nobby correctieketting 10-45 x 3 cm - 1 st   \n",
       "1                                                                 Bore Snake Kaliber 410   \n",
       "2                          Homey's Machete Fieldpal - Zwart Staal - Rubber - Glad Lemmet   \n",
       "3                                                       Petsafe Easy Walk Anti-Trek Rood   \n",
       "4                                                              Joker CR18 vaststaand mes   \n",
       "..                                                                                   ...   \n",
       "647                                        HGHLF Cloud Grinder Precision 2-delig (Zwart)   \n",
       "648                                             Gerber Bear Grylls Folding Sheath Zakmes   \n",
       "649             vidaXL Trainingsband - omtrek tot 70 cm - 7 standen - spatwaterbestendig   \n",
       "650                                            ANTI BLAFBAND PRO MET STATISCHE CORRECTIE   \n",
       "651  10 zwarte cones/holders/Tubes voor sigaretten - Joints - Te bewaren - Te beschermen   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ProductDescriptionNL  \\\n",
       "0                                                                                                                                                                                                                De Nobby correctieketting is gemaakt met het oog op kwaliteit, duurzaamheid en draagcomfort. De ketting bestaat uit schakels.<br /><br />Doordat de halsband kleiner wordt wanneer je hond trekt corrigeert hij zichzelf zodat het onplezierige gevoel van een strakke halsband verdwijnt. <br /><br />In verschillende maten verkrijgbaar.<br />- Afmetingen: 3 MM X 45 CM<br /><br />- Geleverd per: 1 ST   \n",
       "1    <p> Poets de loop van u wapen in 10 seconden met een equivalent van 160 poetsdoekjes. In een enkele poetsbeurt!<br /> </p><p> <br /> </p><h3>Wat is een Bore Snake?</h3><p> De Bore Snake is een lange koord uit geweven katoen met aan de voorkant een gewicht uit messing. De Bore Snake bestaat uit 2 delen, een trekkoord om hem door de loop te krijgen en een poetsgedeelte. Het begin van de Bore Snake bestaat uit een grootte gepofte bal van katoen waar je wapen olie, wapen poets middel of iets anders op kan doen.  Verderop in de Bore Snake bevindt zich een borstel van met messing, gevolgd door e...   \n",
       "2    What’s in a name?! Fieldpal is de maat waar je niet zonder kunt als je je in kampeer-/survivaltochten begeeft. Een kapmes waarmee je je een weg door de jungle baant, een kokosnoot openhakt of riet aan de waterkant kapt voor een perfecte visstek.<br /><br />De Fieldpal machete is uitermate geschikt voor de landbouw en dan vooral bij het kappen van (suiker)riet. Een onmisbaar werktuig dus!<br />In tegenstelling tot vele andere machetes, waarvan het lemmet niet roestbestendig is, is het lemmet van Fieldpal van 420 roestvrij staal. Daarbij is het lemmet zwart voor een tactische look!<br />Het ...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                      Het Easy Walk harnas is een comfortabel en gemakkelijk om te doen harnas die het lopen met uw huisdier plezierig maakt voor u beiden. De bevestiging voor de lijn geeft u de controle. Voor stress-vrije wandelingen.   \n",
       "4    Een jachtmes van het Spaanse merk Joker met een mooi rood houten handvat.De Joker CR18 vaststaand mes is een jachtmes met een van lemmet van Vanadium Molybdeenstaal. Het handvat is gemaakt van een rood hout. Het mes wordt geleverd inclusief een bruine lederen schede waar het mes mooi in kan worden opgeborgen.<br />Joker is een merk uit Spanje dat reeds bestaat sinds 1987. Zij staan bekend om de traditionele en handgemaakte producten met moderne technologieën. Voor de messen wordt kwaliteitsstaal gebruikt zoals 440, 1095 carbon staal en Sandvick staal. De handvatten worden afgewerkt met oli...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "647                                                                                                                              De HGHLF® Cloud Grinders zijn gefabriceerd uit de hoogste kwaliteit Aircraft Grade Aluminium.<br />Ze zijn onverwoestbaar en gaan voor altijd mee.<br /><br />Uitgerust met de meest geavanceerde curved leeuwen tanden ben je gegarandeerd van de fijnste vermaling.<br />Dankzij de neodynium magneet sluitingssysteem blijft je grinder ook gesloten wanneer je on the go bent!<br /><br />HGHLF is het nummer 1 merk op vlak van rol accessoires.<br />HGHLF - First Class Rolling Gear   \n",
       "648  Gerber Bear Grylls Folding Sheath Zakmes is gemaakt voor mensen die een volwaardig mes willen, maar wel compact, inklapbaar en geschikt om op te bergen in een foedraal aan de riem.<br /><br />Kenmerken:<br />• ½ gekarteld droppoint lemmet van RVS met een hoog koolstofgehalte - ideaal voor randscherpte en het snijden van touw<br />• Duimsteun aan twee kanten - voor eenvoudig eenhandig openen<br />• Ergonomische rubberen structuurhandgreep - maximaal comfort en minimaal wegglijden<br />• Lock back - vergrendelt het lemmet stevig en zorgt voor maximale veiligheid bij inklappen<br />• Nylon fo...   \n",
       "649  <p>   Deze humane hondentrainhalsband geeft eerst een onschuldig waarschuwingsgeluid voor dat de halsband steeds zwaardere schokken geeft als de hond blijft blaffen. Hij schakelt door 7 correctieniveau's. Na 7 opeenvolgende schokken schakelt de halsband in een automatische beschermmodus van 1 minuut. Deze handige trainingshalsband heeft een aanpasbare gevoeligheid om te passen bij verschillende honden. Hij heeft een aanpasbare halsband die past tot nekomtrekken van 70 cm. Doordat de halsband gemaakt is van hoogwaardig ABS, is deze trainingshalsband spatwaterbestendig en gaat hij lang mee. ...   \n",
       "650  Nieuwste high-tech band van het het alom geprezen merk Furline®, die zowel een vibratie al waarschuwing gebruikt, evenals een schokje om u te helpen bij de training van uw hond. Nu de doorontwikkelde Pro versie met verbeterde gevoeligheid, en oplaadbaar dus geen gedoe met batterijen!<br /><br />Deze kwaliteitsband heeft een garantie van 10 jaar!<br /><br />Deze halsband is een zeer effectief gedragsveranderings apparaat om te helpen trainen uw hond te blaffen overlast en slecht gedrag te stoppen. Als uw hond blaft, geeft de Furline Pro band een vibratie samen met een licht schokje. Het hoo...   \n",
       "651                                                                               Niets zo ambetant als sigaretten of andere dingen die breken in uw zak tijdens het wandelen.<br />Dat is vanaf nu verleden tijd met deze 10 cones.<br />Speciaal in een zwarte kleur zodat de zon er niet kan doorkomen.<br /><br /><br />Indien u meer als 10 stuks wilt bestellen, heeft u recht op aanvraag van een offerte.<br />Aarzel niet om ons te contacteren en wij beloven een mooie korting voor grotere hoeveelheden.<br />Bij ECOSTAREGENT staan een snelle levering, kwaliteit, mooie verpakking en goede service centraal.   \n",
       "\n",
       "                                                                       BrickName  \\\n",
       "0    Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "1                                                          Buiten/Tuin Speelgoed   \n",
       "2                                                  Hobbymessen (Niet-elektrisch)   \n",
       "3    Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "4                                                  Hobbymessen (Niet-elektrisch)   \n",
       "..                                                                           ...   \n",
       "647                                             Keuken Snij-/Rasp-/Haktoestellen   \n",
       "648                                                Hobbymessen (Niet-elektrisch)   \n",
       "649  Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "650  Training/Controle Hulpmiddelen/Toebehoren voor Huisdieren (Niet-elektrisch)   \n",
       "651                                                              Rookaccessoires   \n",
       "\n",
       "                      ChunkName                 BrandName  \\\n",
       "0            Opvoedingshalsband                     Nobby   \n",
       "1    Schietspeelgoedaccessoires  Cobra Tactical Solutions   \n",
       "2                        Zakmes    HOMEY’s TOOLS FOR LIFE   \n",
       "3            Opvoedingshalsband                   PetSafe   \n",
       "4                        Zakmes                     Joker   \n",
       "..                          ...                       ...   \n",
       "647                 Keukenmolen                     HGHLF   \n",
       "648                      Zakmes                    Gerber   \n",
       "649          Opvoedingshalsband                    vidaXL   \n",
       "650          Opvoedingshalsband               Furline Pro   \n",
       "651  Accessoire voor sigaretten                  ECOSTARE   \n",
       "\n",
       "                         Colour        Material  NumberOfProductsInPackage  \\\n",
       "0                         Grijs          Metaal                        NaN   \n",
       "1                           NaN  100% polyester                        NaN   \n",
       "2                         Zwart          Rubber                        NaN   \n",
       "3                          Rood             NaN                        NaN   \n",
       "4    Zilver met roodachtig hout            Hout                        NaN   \n",
       "..                          ...             ...                        ...   \n",
       "647                 Pitch Black       Aluminium                        NaN   \n",
       "648              Oranje / zwart          Rubber                        NaN   \n",
       "649                       zwart       Kunststof                        NaN   \n",
       "650                       zwart       Polyester                        NaN   \n",
       "651                       Zwart         Plastic                        NaN   \n",
       "\n",
       "     PackageHeight PackageHeightUnit  ...  text_758  text_759  text_760  \\\n",
       "0              NaN               NaN  ...  0.507512  0.735776  0.798402   \n",
       "1              NaN               NaN  ...  0.188966  0.871161 -0.247050   \n",
       "2             40.0    unece.unit.MMT  ...  0.340339  0.713510  0.043395   \n",
       "3              NaN               NaN  ...  0.409554  0.716285  0.739491   \n",
       "4              4.5    unece.unit.CMT  ...  0.242094  0.518071 -0.208649   \n",
       "..             ...               ...  ...       ...       ...       ...   \n",
       "647           38.0    unece.unit.MMT  ...  0.331174  0.607316 -0.163724   \n",
       "648           50.0    unece.unit.MMT  ...  0.706961  0.674504  0.147302   \n",
       "649            NaN               NaN  ...  0.301048  0.729011 -0.058431   \n",
       "650           52.0    unece.unit.MMT  ...  0.532541  0.743138  0.222930   \n",
       "651           62.0    unece.unit.MMT  ...  0.644087  0.736305  0.386134   \n",
       "\n",
       "     text_761  text_762  text_763  text_764  text_765  text_766  text_767  \n",
       "0   -0.225944  0.348368  0.010767  0.281298  0.604051  0.204834  0.107701  \n",
       "1   -0.036275  0.358823  0.060928  0.537199  0.382411  0.213614  0.933042  \n",
       "2    0.011456  0.609852  0.122007  0.546514  0.567774 -0.065915  0.758254  \n",
       "3   -0.395622  0.375344  0.133185  0.062893  0.549106  0.210281 -0.268637  \n",
       "4    0.047773  0.322289  0.064792  0.736442  0.377610 -0.072555  1.174717  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "647 -0.009131  0.510441 -0.000068  0.697754  0.285001  0.040795  1.127209  \n",
       "648 -0.007659  0.655224 -0.200165  0.675610  0.271636  0.171715  1.064215  \n",
       "649 -0.068579  0.364053 -0.063120  0.435569  0.421877  0.433908  0.849236  \n",
       "650 -0.012161  0.677762 -0.051846  0.510310  0.380803  0.012688  0.899228  \n",
       "651 -0.077947  0.702133  0.016595  0.431552  0.591613  0.111937  0.617980  \n",
       "\n",
       "[652 rows x 796 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_names = [str(i) for i in range(768)]\n",
    "rename_cols = {i: \"text_\"+i for i in em_names}\n",
    "\n",
    "train_data_new = pd.concat([test_data, test_data_text_with_embeddings[em_names]],axis=1)\n",
    "train_data_new = train_data_new.rename(rename_cols,axis=1)\n",
    "train_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "polyphonic-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train_data_new.to_csv(\"./data/featurized/V2/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-interim",
   "metadata": {},
   "source": [
    "# Featurazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "asian-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# - LabelName is all null, drop it; GlobalId has no value, drop it. Ingredients is also all null\n",
    "# - MaterialDescription has only 1 value, which is not useful;\n",
    "# - NumberOfPieces has 3 values, not useful\n",
    "def drop_columns(df):\n",
    "    df_local = df.copy(deep=True)\n",
    "    cols_drop = [\"GlobalID\", \"LabelName\", \"Ingredients\", \"MaterialDescription\", \"NumberOfPieces\"]\n",
    "    df_local = df_local.drop(cols_drop,axis=1)\n",
    "    return df_local\n",
    "\n",
    "\n",
    "def add_binary_feature(df):\n",
    "    df_local = df.copy(deep=True)\n",
    "    # if the feature is null, then 0, otherwise 1\n",
    "    df_local[\"hasTitle\"] = np.where(df_local['ProductTitleNL'].isnull(), 0, 1)\n",
    "    df_local[\"hasDesc\"] = np.where(df_local['ProductDescriptionNL'].isnull(), 0, 1)\n",
    "    df_local[\"has_image_url\"] = np.where(df_local['image_url'].isnull(), 0, 1)\n",
    "    return df_local\n",
    "\n",
    "def featurize(df):\n",
    "    _df = df.copy(deep=True)\n",
    "    # drop columns\n",
    "    _df = drop_columns(_df)\n",
    "    _df = add_binary_feature(_df)\n",
    "    return _df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-legislature",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model 2: only tabular default models but with larger stacking\n",
    "\n",
    "- `WeightedEnsemble_L3` has the best validation score on condabench (acc 0.8902821317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "equivalent-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN': {},\n",
       " 'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
       "  {},\n",
       "  'GBMLarge'],\n",
       " 'CAT': {},\n",
       " 'XGB': {},\n",
       " 'FASTAI': {},\n",
       " 'RF': [{'criterion': 'gini',\n",
       "   'ag_args': {'name_suffix': 'Gini',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'entropy',\n",
       "   'ag_args': {'name_suffix': 'Entr',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'mse',\n",
       "   'ag_args': {'name_suffix': 'MSE',\n",
       "    'problem_types': ['regression', 'quantile']}}],\n",
       " 'XT': [{'criterion': 'gini',\n",
       "   'ag_args': {'name_suffix': 'Gini',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'entropy',\n",
       "   'ag_args': {'name_suffix': 'Entr',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'mse',\n",
       "   'ag_args': {'name_suffix': 'MSE',\n",
       "    'problem_types': ['regression', 'quantile']}}],\n",
       " 'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}},\n",
       "  {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\n",
    "default_hp_config = get_hyperparameter_config(\"default\")\n",
    "default_hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "pleased-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"model2_tabular_featurizedV2\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'ag_args_fit': {'num_gpus': 1}, 'auto_stack': True, 'save_space': True}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': True,\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'quantile_levels': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': True,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"model2_tabular_featurizedV2/\"\n",
      "AutoGluon Version:  0.2.1b20210517\n",
      "Train Data Rows:    2968\n",
      "Train Data Columns: 796\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Y', 'N']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Y, class 0 = N\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Y) vs negative (N) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    54621.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 23.99 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int64', 'int')     :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('object', 'object') :  16 | ['ProductTitleNL', 'ProductDescriptionNL', 'BrickName', 'ChunkName', 'BrandName', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])        : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])          :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('object', [])       :  14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('object', ['text']) :   2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])        : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])          :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('object', [])       :  14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('object', ['text']) :   2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t796 features in original data used to generate 796 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])        : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])          :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('object', [])       :  14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('object', ['text']) :   2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])        : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])          :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('object', [])       :  14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('object', ['text']) :   2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t796 features in original data used to generate 796 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])   :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])   :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t780 features in original data used to generate 780 features in processed data.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', [])                   : 14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', [])                   : 14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t\t0.0s = Fit runtime\n",
      "\t\t\t\t16 features in original data used to generate 16 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', [])       : 14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('object', ['text']) :  2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])                   : 14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('category', ['text_as_category']) :  2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t16 features in original data used to generate 16 features in processed data.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('float', ['text_special']) : 40 | ['ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', 'ProductTitleNL.special_ratio', 'ProductTitleNL.symbol_ratio.!', ...]\n",
      "\t\t\t\t\t('int', ['text_special'])   : 36 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.symbol_count.!', 'ProductTitleNL.symbol_count.?', 'ProductTitleNL.symbol_count.@', ...]\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('int', ['binned', 'text_special']) : 76 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t\t\t1.0s = Fit runtime\n",
      "\t\t\t\t76 features in original data used to generate 76 features in processed data.\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\t\t13 duplicate columns removed: ['ProductTitleNL.symbol_ratio.?', 'ProductTitleNL.symbol_ratio.@', 'ProductTitleNL.symbol_count.$', 'ProductTitleNL.symbol_ratio.$', 'ProductTitleNL.symbol_count.^', 'ProductTitleNL.symbol_ratio.^', 'ProductTitleNL.symbol_count.;', 'ProductTitleNL.symbol_ratio.;', 'ProductDescriptionNL.symbol_count.$', 'ProductDescriptionNL.symbol_ratio.$', 'ProductDescriptionNL.symbol_count.^', 'ProductDescriptionNL.symbol_ratio.^', 'ProductDescriptionNL.symbol_ratio.@']\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t('int', ['binned', 'text_special']) : 63 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('int', ['binned', 'text_special']) : 63 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t\t\t3.1s = Fit runtime\n",
      "\t\t\t\t63 features in original data used to generate 63 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', ['text']) : 2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['binned', 'text_special']) : 63 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t\t5.9s = Fit runtime\n",
      "\t\t\t2 features in original data used to generate 63 features in processed data.\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
      "                ngram_range=(1, 3))\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2265\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', ['text']) : 2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['text_ngram']) : 2266 | ['__nlp__.10', '__nlp__.10 cm', '__nlp__.10 ml', '__nlp__.10 ml en', '__nlp__.10 ml wat', ...]\n",
      "\t\t\t2.8s = Fit runtime\n",
      "\t\t\t2 features in original data used to generate 2266 features in processed data.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])                    :   14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('category', ['text_as_category'])  :    2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t\t('float', [])                       :  777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])                         :    3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('int', ['binned', 'text_special']) :   62 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t\t\t('int', ['text_ngram'])             : 2266 | ['__nlp__.10', '__nlp__.10 cm', '__nlp__.10 ml', '__nlp__.10 ml en', '__nlp__.10 ml wat', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])                    :   14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t\t\t('category', ['text_as_category'])  :    2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t\t\t('float', [])                       :  777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t\t\t('int', [])                         :    3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t\t\t('int', ['binned', 'text_special']) :   62 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t\t\t('int', ['text_ngram'])             : 2266 | ['__nlp__.10', '__nlp__.10 cm', '__nlp__.10 ml', '__nlp__.10 ml en', '__nlp__.10 ml wat', ...]\n",
      "\t\t\t0.9s = Fit runtime\n",
      "\t\t\t3124 features in original data used to generate 3124 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t('int64', 'int')     :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t('object', 'object') :  16 | ['ProductTitleNL', 'ProductDescriptionNL', 'BrickName', 'ChunkName', 'BrandName', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t('int', [])          :   3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t('object', [])       :  14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t('object', ['text']) :   2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') :   16 | ['ProductTitleNL', 'ProductDescriptionNL', 'BrickName', 'ChunkName', 'BrandName', ...]\n",
      "\t\t('float64', 'float')     :  777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t('int32', 'int')         :    1 | ['__nlp__._total_']\n",
      "\t\t('int64', 'int')         :    3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t('uint8', 'int')         : 2327 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   14 | ['BrickName', 'ChunkName', 'BrandName', 'Colour', 'Material', ...]\n",
      "\t\t('category', ['text_as_category'])  :    2 | ['ProductTitleNL', 'ProductDescriptionNL']\n",
      "\t\t('float', [])                       :  777 | ['NumberOfProductsInPackage', 'PackageHeight', 'PackageLength', 'PackageWeight', 'PackageWidth', ...]\n",
      "\t\t('int', [])                         :    3 | ['hasTitle', 'hasDesc', 'has_image_url']\n",
      "\t\t('int', ['binned', 'text_special']) :   62 | ['ProductTitleNL.char_count', 'ProductTitleNL.word_count', 'ProductTitleNL.capital_ratio', 'ProductTitleNL.lower_ratio', 'ProductTitleNL.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 2266 | ['__nlp__.10', '__nlp__.10 cm', '__nlp__.10 ml', '__nlp__.10 ml en', '__nlp__.10 ml wat', ...]\n",
      "\t11.1s = Fit runtime\n",
      "\t796 features in original data used to generate 3124 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 25.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Saving model2_tabular_featurizedV2/learner.pkl\n",
      "Saving model2_tabular_featurizedV2/utils/data/X.pkl\n",
      "Saving model2_tabular_featurizedV2/utils/data/y.pkl\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetMXNet_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.tabular_nn_model.TabularNeuralNetModel'>, 'priority': 20}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t0.814\t = Validation accuracy score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t0.8187\t = Validation accuracy score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0415575\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0.00861101\tvalid_set's binary_error: 0.0909091\n",
      "[150]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0875421\n",
      "[200]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0942761\n",
      "[250]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0942761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0393111\tvalid_set's binary_error: 0.0740741\n",
      "[100]\ttrain_set's binary_error: 0.0101086\tvalid_set's binary_error: 0.0707071\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0740741\n",
      "[200]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0396855\tvalid_set's binary_error: 0.111111\n",
      "[100]\ttrain_set's binary_error: 0.00786222\tvalid_set's binary_error: 0.111111\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0426806\tvalid_set's binary_error: 0.0707071\n",
      "[100]\ttrain_set's binary_error: 0.00823662\tvalid_set's binary_error: 0.0639731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0639731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0415575\tvalid_set's binary_error: 0.0875421\n",
      "[100]\ttrain_set's binary_error: 0.010483\tvalid_set's binary_error: 0.0875421\n",
      "[150]\ttrain_set's binary_error: 0.0044927\tvalid_set's binary_error: 0.0875421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.043055\tvalid_set's binary_error: 0.0942761\n",
      "[100]\ttrain_set's binary_error: 0.00823662\tvalid_set's binary_error: 0.0942761\n",
      "[150]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0942761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0434294\tvalid_set's binary_error: 0.0639731\n",
      "[100]\ttrain_set's binary_error: 0.00935979\tvalid_set's binary_error: 0.0538721\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0396855\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0.00861101\tvalid_set's binary_error: 0.0875421\n",
      "[150]\ttrain_set's binary_error: 0.00411831\tvalid_set's binary_error: 0.0740741\n",
      "[200]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0875421\n",
      "[250]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0875421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0875421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0422904\tvalid_set's binary_error: 0.0709459\n",
      "[100]\ttrain_set's binary_error: 0.00898204\tvalid_set's binary_error: 0.0675676\n",
      "[150]\ttrain_set's binary_error: 0.00411677\tvalid_set's binary_error: 0.0709459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0415419\tvalid_set's binary_error: 0.0641892\n",
      "[100]\ttrain_set's binary_error: 0.0123503\tvalid_set's binary_error: 0.0743243\n",
      "[150]\ttrain_set's binary_error: 0.00449102\tvalid_set's binary_error: 0.0743243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9292\t = Validation accuracy score\n",
      "\t73.98s\t = Training runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0194684\tvalid_set's binary_error: 0.0841751\n",
      "[100]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0909091\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0875421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0209659\tvalid_set's binary_error: 0.0808081\n",
      "[100]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0740741\n",
      "[150]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0740741\n",
      "[200]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0774411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0183452\tvalid_set's binary_error: 0.121212\n",
      "[100]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.111111\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.114478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0202171\tvalid_set's binary_error: 0.0673401\n",
      "[100]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0639731\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0639731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0205915\tvalid_set's binary_error: 0.0841751\n",
      "[100]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0841751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0179708\tvalid_set's binary_error: 0.0841751\n",
      "[100]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0841751\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0808081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0228379\tvalid_set's binary_error: 0.0606061\n",
      "[100]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0572391\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0606061\n",
      "[200]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0572391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0168476\tvalid_set's binary_error: 0.0942761\n",
      "[100]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0740741\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0707071\n",
      "[200]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0774411\n",
      "[250]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0774411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0172156\tvalid_set's binary_error: 0.0743243\n",
      "[100]\ttrain_set's binary_error: 0.00336826\tvalid_set's binary_error: 0.0810811\n",
      "[150]\ttrain_set's binary_error: 0.00336826\tvalid_set's binary_error: 0.0743243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0213323\tvalid_set's binary_error: 0.0777027\n",
      "[100]\ttrain_set's binary_error: 0.00523952\tvalid_set's binary_error: 0.0743243\n",
      "[150]\ttrain_set's binary_error: 0.00374251\tvalid_set's binary_error: 0.0709459\n",
      "[200]\ttrain_set's binary_error: 0.00374251\tvalid_set's binary_error: 0.0675676\n",
      "[250]\ttrain_set's binary_error: 0.00374251\tvalid_set's binary_error: 0.0675676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9282\t = Validation accuracy score\n",
      "\t150.39s\t = Training runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\t0.9235\t = Validation accuracy score\n",
      "\t3.53s\t = Training runtime\n",
      "\t3.73s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\t0.9235\t = Validation accuracy score\n",
      "\t3.64s\t = Training runtime\n",
      "\t3.61s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9165107\ttest: 0.9090909\tbest: 0.9090909 (0)\ttotal: 123ms\tremaining: 20m 28s\n",
      "20:\tlearn: 0.9228753\ttest: 0.9124579\tbest: 0.9124579 (16)\ttotal: 2.67s\tremaining: 21m 6s\n",
      "40:\tlearn: 0.9251217\ttest: 0.9124579\tbest: 0.9124579 (16)\ttotal: 5.05s\tremaining: 20m 27s\n",
      "60:\tlearn: 0.9262449\ttest: 0.9124579\tbest: 0.9124579 (16)\ttotal: 7.73s\tremaining: 20m 59s\n",
      "80:\tlearn: 0.9273680\ttest: 0.9124579\tbest: 0.9124579 (16)\ttotal: 10.5s\tremaining: 21m 21s\n",
      "100:\tlearn: 0.9288656\ttest: 0.9124579\tbest: 0.9124579 (16)\ttotal: 13.1s\tremaining: 21m 24s\n",
      "120:\tlearn: 0.9314863\ttest: 0.9057239\tbest: 0.9124579 (16)\ttotal: 15.7s\tremaining: 21m 24s\n",
      "140:\tlearn: 0.9322351\ttest: 0.9090909\tbest: 0.9124579 (16)\ttotal: 18.3s\tremaining: 21m 19s\n",
      "160:\tlearn: 0.9348559\ttest: 0.9057239\tbest: 0.9124579 (16)\ttotal: 20.9s\tremaining: 21m 14s\n",
      "bestTest = 0.9124579125\n",
      "bestIteration = 16\n",
      "Shrink model to first 17 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9157619\ttest: 0.9090909\tbest: 0.9090909 (0)\ttotal: 90.7ms\tremaining: 15m 6s\n",
      "20:\tlearn: 0.9232497\ttest: 0.9124579\tbest: 0.9191919 (4)\ttotal: 2.64s\tremaining: 20m 56s\n",
      "40:\tlearn: 0.9228753\ttest: 0.9124579\tbest: 0.9191919 (4)\ttotal: 5.28s\tremaining: 21m 23s\n",
      "60:\tlearn: 0.9254961\ttest: 0.9158249\tbest: 0.9191919 (4)\ttotal: 7.95s\tremaining: 21m 35s\n",
      "80:\tlearn: 0.9269936\ttest: 0.9191919\tbest: 0.9191919 (4)\ttotal: 10.7s\tremaining: 21m 44s\n",
      "100:\tlearn: 0.9292400\ttest: 0.9191919\tbest: 0.9191919 (4)\ttotal: 13.3s\tremaining: 21m 43s\n",
      "120:\tlearn: 0.9299888\ttest: 0.9191919\tbest: 0.9191919 (4)\ttotal: 15.8s\tremaining: 21m 31s\n",
      "140:\tlearn: 0.9303632\ttest: 0.9191919\tbest: 0.9191919 (4)\ttotal: 18.3s\tremaining: 21m 20s\n",
      "bestTest = 0.9191919192\n",
      "bestIteration = 4\n",
      "Shrink model to first 5 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9195058\ttest: 0.8787879\tbest: 0.8787879 (0)\ttotal: 128ms\tremaining: 21m 24s\n",
      "20:\tlearn: 0.9236241\ttest: 0.8821549\tbest: 0.8855219 (1)\ttotal: 2.54s\tremaining: 20m 5s\n",
      "40:\tlearn: 0.9258705\ttest: 0.8821549\tbest: 0.8855219 (1)\ttotal: 4.92s\tremaining: 19m 53s\n",
      "60:\tlearn: 0.9281168\ttest: 0.8821549\tbest: 0.8855219 (1)\ttotal: 7.47s\tremaining: 20m 17s\n",
      "80:\tlearn: 0.9296144\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 10.1s\tremaining: 20m 34s\n",
      "100:\tlearn: 0.9322351\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 12.7s\tremaining: 20m 46s\n",
      "120:\tlearn: 0.9337327\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 15.3s\tremaining: 20m 47s\n",
      "140:\tlearn: 0.9333583\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 17.8s\tremaining: 20m 46s\n",
      "160:\tlearn: 0.9341071\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 20.4s\tremaining: 20m 45s\n",
      "180:\tlearn: 0.9356046\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 22.7s\tremaining: 20m 33s\n",
      "200:\tlearn: 0.9363534\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 25.2s\tremaining: 20m 28s\n",
      "220:\tlearn: 0.9371022\ttest: 0.8888889\tbest: 0.8888889 (77)\ttotal: 27.7s\tremaining: 20m 23s\n",
      "bestTest = 0.8888888889\n",
      "bestIteration = 77\n",
      "Shrink model to first 78 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9157619\ttest: 0.9259259\tbest: 0.9259259 (0)\ttotal: 85.2ms\tremaining: 14m 12s\n",
      "20:\tlearn: 0.9198802\ttest: 0.9225589\tbest: 0.9326599 (3)\ttotal: 2.45s\tremaining: 19m 24s\n",
      "40:\tlearn: 0.9210034\ttest: 0.9225589\tbest: 0.9326599 (3)\ttotal: 4.96s\tremaining: 20m 4s\n",
      "60:\tlearn: 0.9217522\ttest: 0.9225589\tbest: 0.9326599 (3)\ttotal: 7.55s\tremaining: 20m 29s\n",
      "80:\tlearn: 0.9232497\ttest: 0.9225589\tbest: 0.9326599 (3)\ttotal: 10.2s\tremaining: 20m 44s\n",
      "100:\tlearn: 0.9251217\ttest: 0.9158249\tbest: 0.9326599 (3)\ttotal: 12.8s\tremaining: 20m 57s\n",
      "120:\tlearn: 0.9266192\ttest: 0.9225589\tbest: 0.9326599 (3)\ttotal: 15.4s\tremaining: 20m 57s\n",
      "140:\tlearn: 0.9281168\ttest: 0.9191919\tbest: 0.9326599 (3)\ttotal: 18s\tremaining: 20m 56s\n",
      "bestTest = 0.9326599327\n",
      "bestIteration = 3\n",
      "Shrink model to first 4 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9183826\ttest: 0.8989899\tbest: 0.8989899 (0)\ttotal: 120ms\tremaining: 20m\n",
      "20:\tlearn: 0.9225009\ttest: 0.9124579\tbest: 0.9225589 (4)\ttotal: 2.56s\tremaining: 20m 17s\n",
      "40:\tlearn: 0.9228753\ttest: 0.9124579\tbest: 0.9225589 (4)\ttotal: 4.94s\tremaining: 20m\n",
      "60:\tlearn: 0.9251217\ttest: 0.9158249\tbest: 0.9225589 (4)\ttotal: 7.77s\tremaining: 21m 6s\n",
      "80:\tlearn: 0.9251217\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 10.5s\tremaining: 21m 27s\n",
      "100:\tlearn: 0.9262449\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 13.2s\tremaining: 21m 32s\n",
      "120:\tlearn: 0.9284912\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 15.8s\tremaining: 21m 30s\n",
      "140:\tlearn: 0.9292400\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 18.4s\tremaining: 21m 28s\n",
      "160:\tlearn: 0.9292400\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 21s\tremaining: 21m 21s\n",
      "180:\tlearn: 0.9303632\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 23.4s\tremaining: 21m 11s\n",
      "200:\tlearn: 0.9314863\ttest: 0.9259259\tbest: 0.9259259 (75)\ttotal: 25.8s\tremaining: 20m 59s\n",
      "220:\tlearn: 0.9314863\ttest: 0.9225589\tbest: 0.9259259 (75)\ttotal: 28.4s\tremaining: 20m 55s\n",
      "bestTest = 0.9259259259\n",
      "bestIteration = 75\n",
      "Shrink model to first 76 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9153875\ttest: 0.9259259\tbest: 0.9259259 (0)\ttotal: 121ms\tremaining: 20m 5s\n",
      "20:\tlearn: 0.9202546\ttest: 0.9259259\tbest: 0.9259259 (0)\ttotal: 2.58s\tremaining: 20m 24s\n",
      "40:\tlearn: 0.9210034\ttest: 0.9225589\tbest: 0.9259259 (0)\ttotal: 5.01s\tremaining: 20m 16s\n",
      "60:\tlearn: 0.9236241\ttest: 0.9158249\tbest: 0.9259259 (0)\ttotal: 7.73s\tremaining: 21m\n",
      "80:\tlearn: 0.9262449\ttest: 0.9158249\tbest: 0.9259259 (0)\ttotal: 10.5s\tremaining: 21m 23s\n",
      "100:\tlearn: 0.9284912\ttest: 0.9158249\tbest: 0.9259259 (0)\ttotal: 13.1s\tremaining: 21m 28s\n",
      "120:\tlearn: 0.9307376\ttest: 0.9191919\tbest: 0.9259259 (0)\ttotal: 15.7s\tremaining: 21m 25s\n",
      "140:\tlearn: 0.9311119\ttest: 0.9191919\tbest: 0.9259259 (0)\ttotal: 18.3s\tremaining: 21m 19s\n",
      "bestTest = 0.9259259259\n",
      "bestIteration = 0\n",
      "Shrink model to first 1 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9127668\ttest: 0.9393939\tbest: 0.9393939 (0)\ttotal: 132ms\tremaining: 21m 59s\n",
      "20:\tlearn: 0.9195058\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 2.51s\tremaining: 19m 53s\n",
      "40:\tlearn: 0.9228753\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 5.02s\tremaining: 20m 19s\n",
      "60:\tlearn: 0.9221265\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 7.69s\tremaining: 20m 52s\n",
      "80:\tlearn: 0.9228753\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 10.3s\tremaining: 20m 55s\n",
      "100:\tlearn: 0.9254961\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 12.8s\tremaining: 20m 58s\n",
      "120:\tlearn: 0.9273680\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 15.4s\tremaining: 20m 59s\n",
      "140:\tlearn: 0.9277424\ttest: 0.9393939\tbest: 0.9461279 (6)\ttotal: 18s\tremaining: 20m 57s\n",
      "bestTest = 0.9461279461\n",
      "bestIteration = 6\n",
      "Shrink model to first 7 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9116436\ttest: 0.8989899\tbest: 0.8989899 (0)\ttotal: 85.3ms\tremaining: 14m 12s\n",
      "20:\tlearn: 0.9251217\ttest: 0.9057239\tbest: 0.9057239 (6)\ttotal: 2.44s\tremaining: 19m 21s\n",
      "40:\tlearn: 0.9273680\ttest: 0.9057239\tbest: 0.9057239 (6)\ttotal: 4.83s\tremaining: 19m 34s\n",
      "60:\tlearn: 0.9266192\ttest: 0.9090909\tbest: 0.9090909 (59)\ttotal: 7.46s\tremaining: 20m 16s\n",
      "80:\tlearn: 0.9273680\ttest: 0.9090909\tbest: 0.9090909 (59)\ttotal: 10.1s\tremaining: 20m 32s\n",
      "100:\tlearn: 0.9296144\ttest: 0.9158249\tbest: 0.9158249 (88)\ttotal: 12.6s\tremaining: 20m 37s\n",
      "120:\tlearn: 0.9303632\ttest: 0.9158249\tbest: 0.9158249 (88)\ttotal: 15.1s\tremaining: 20m 36s\n",
      "140:\tlearn: 0.9299888\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 17.7s\tremaining: 20m 38s\n",
      "160:\tlearn: 0.9322351\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 20.2s\tremaining: 20m 34s\n",
      "180:\tlearn: 0.9333583\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 22.6s\tremaining: 20m 26s\n",
      "200:\tlearn: 0.9341071\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 25s\tremaining: 20m 19s\n",
      "220:\tlearn: 0.9341071\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 27.4s\tremaining: 20m 12s\n",
      "240:\tlearn: 0.9337327\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 29.8s\tremaining: 20m 8s\n",
      "260:\tlearn: 0.9344815\ttest: 0.9191919\tbest: 0.9191919 (128)\ttotal: 32.2s\tremaining: 20m 2s\n",
      "bestTest = 0.9191919192\n",
      "bestIteration = 128\n",
      "Shrink model to first 129 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9124251\ttest: 0.9222973\tbest: 0.9222973 (0)\ttotal: 85.7ms\tremaining: 14m 17s\n",
      "20:\tlearn: 0.9236527\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 2.47s\tremaining: 19m 34s\n",
      "40:\tlearn: 0.9217814\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 4.91s\tremaining: 19m 53s\n",
      "60:\tlearn: 0.9244012\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 7.54s\tremaining: 20m 28s\n",
      "80:\tlearn: 0.9244012\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 10.1s\tremaining: 20m 39s\n",
      "100:\tlearn: 0.9262725\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 12.7s\tremaining: 20m 43s\n",
      "120:\tlearn: 0.9255240\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 15.2s\tremaining: 20m 42s\n",
      "140:\tlearn: 0.9273952\ttest: 0.9358108\tbest: 0.9358108 (4)\ttotal: 17.9s\tremaining: 20m 48s\n",
      "bestTest = 0.9358108108\n",
      "bestIteration = 4\n",
      "Shrink model to first 5 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9154192\ttest: 0.9290541\tbest: 0.9290541 (0)\ttotal: 125ms\tremaining: 20m 54s\n",
      "20:\tlearn: 0.9210329\ttest: 0.9324324\tbest: 0.9358108 (8)\ttotal: 2.59s\tremaining: 20m 32s\n",
      "40:\tlearn: 0.9232784\ttest: 0.9358108\tbest: 0.9358108 (8)\ttotal: 5.03s\tremaining: 20m 21s\n",
      "60:\tlearn: 0.9244012\ttest: 0.9324324\tbest: 0.9358108 (8)\ttotal: 7.62s\tremaining: 20m 42s\n",
      "80:\tlearn: 0.9247754\ttest: 0.9324324\tbest: 0.9358108 (8)\ttotal: 10.3s\tremaining: 20m 58s\n",
      "100:\tlearn: 0.9266467\ttest: 0.9324324\tbest: 0.9358108 (8)\ttotal: 12.9s\tremaining: 21m 3s\n",
      "120:\tlearn: 0.9285180\ttest: 0.9324324\tbest: 0.9358108 (8)\ttotal: 15.5s\tremaining: 21m 9s\n",
      "140:\tlearn: 0.9285180\ttest: 0.9324324\tbest: 0.9358108 (8)\ttotal: 18.1s\tremaining: 21m 8s\n",
      "160:\tlearn: 0.9292665\ttest: 0.9391892\tbest: 0.9391892 (156)\ttotal: 20.8s\tremaining: 21m 8s\n",
      "180:\tlearn: 0.9311377\ttest: 0.9391892\tbest: 0.9391892 (156)\ttotal: 23.3s\tremaining: 21m 5s\n",
      "200:\tlearn: 0.9322605\ttest: 0.9324324\tbest: 0.9391892 (156)\ttotal: 25.9s\tremaining: 21m 1s\n",
      "220:\tlearn: 0.9333832\ttest: 0.9391892\tbest: 0.9391892 (156)\ttotal: 28.5s\tremaining: 21m 2s\n",
      "240:\tlearn: 0.9345060\ttest: 0.9391892\tbest: 0.9391892 (156)\ttotal: 31s\tremaining: 20m 53s\n",
      "260:\tlearn: 0.9363772\ttest: 0.9391892\tbest: 0.9391892 (156)\ttotal: 33.4s\tremaining: 20m 45s\n",
      "280:\tlearn: 0.9356287\ttest: 0.9391892\tbest: 0.9391892 (156)\ttotal: 35.9s\tremaining: 20m 41s\n",
      "300:\tlearn: 0.9363772\ttest: 0.9358108\tbest: 0.9391892 (156)\ttotal: 38.4s\tremaining: 20m 36s\n",
      "bestTest = 0.9391891892\n",
      "bestIteration = 156\n",
      "Shrink model to first 157 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9245\t = Validation accuracy score\n",
      "\t280.87s\t = Training runtime\n",
      "\t2.9s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\t0.9191\t = Validation accuracy score\n",
      "\t2.44s\t = Training runtime\n",
      "\t3.73s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\t0.9222\t = Validation accuracy score\n",
      "\t2.23s\t = Training runtime\n",
      "\t3.71s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9057239294052124.\n",
      "Better model found at epoch 2 with accuracy value: 0.9090909361839294.\n",
      "Better model found at epoch 4 with accuracy value: 0.9124578833580017.\n",
      "Better model found at epoch 9 with accuracy value: 0.9158248901367188.\n",
      "No improvement since epoch 9: early stopping\n",
      "Model validation metrics: 0.9158248901367188\n",
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9124578833580017.\n",
      "Better model found at epoch 2 with accuracy value: 0.9191918969154358.\n",
      "Better model found at epoch 7 with accuracy value: 0.9225589036941528.\n",
      "Better model found at epoch 12 with accuracy value: 0.9259259104728699.\n",
      "Model validation metrics: 0.9259259104728699\n",
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.8922559022903442.\n",
      "Better model found at epoch 1 with accuracy value: 0.8989899158477783.\n",
      "Better model found at epoch 6 with accuracy value: 0.9090909361839294.\n",
      "Better model found at epoch 8 with accuracy value: 0.9158248901367188.\n",
      "No improvement since epoch 8: early stopping\n",
      "Model validation metrics: 0.9158248901367188\n",
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.9292929172515869.\n",
      "No improvement since epoch 0: early stopping\n",
      "Model validation metrics: 0.9292929172515869\n",
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9259259104728699.\n",
      "Better model found at epoch 1 with accuracy value: 0.9292929172515869.\n",
      "No improvement since epoch 1: early stopping\n",
      "Model validation metrics: 0.9292929172515869\n",
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9124578833580017.\n",
      "Better model found at epoch 14 with accuracy value: 0.9158248901367188.\n",
      "Better model found at epoch 16 with accuracy value: 0.9191918969154358.\n",
      "Model validation metrics: 0.9191918969154358\n",
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.939393937587738.\n",
      "Better model found at epoch 2 with accuracy value: 0.9427609443664551.\n",
      "Better model found at epoch 4 with accuracy value: 0.9461279511451721.\n",
      "No improvement since epoch 4: early stopping\n",
      "Model validation metrics: 0.9461279511451721\n",
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9124578833580017.\n",
      "Better model found at epoch 9 with accuracy value: 0.9158248901367188.\n",
      "Better model found at epoch 10 with accuracy value: 0.9191918969154358.\n",
      "Better model found at epoch 12 with accuracy value: 0.9259259104728699.\n",
      "Model validation metrics: 0.9259259104728699\n",
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.9358108043670654.\n",
      "Better model found at epoch 1 with accuracy value: 0.9391891956329346.\n",
      "Better model found at epoch 2 with accuracy value: 0.9425675868988037.\n",
      "Better model found at epoch 10 with accuracy value: 0.9459459185600281.\n",
      "Model validation metrics: 0.9459459185600281\n",
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3108 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3684, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9290540814399719.\n",
      "No improvement since epoch 0: early stopping\n",
      "Model validation metrics: 0.9290540814399719\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9282\t = Validation accuracy score\n",
      "\t242.48s\t = Training runtime\n",
      "\t16.89s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.08754\n",
      "[50]\tvalidation_0-error:0.09091\n",
      "[100]\tvalidation_0-error:0.09091\n",
      "[150]\tvalidation_0-error:0.09428\n",
      "[157]\tvalidation_0-error:0.09428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.12458\n",
      "[50]\tvalidation_0-error:0.07071\n",
      "[100]\tvalidation_0-error:0.07071\n",
      "[150]\tvalidation_0-error:0.07407\n",
      "[181]\tvalidation_0-error:0.07407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.12121\n",
      "[50]\tvalidation_0-error:0.10774\n",
      "[100]\tvalidation_0-error:0.10774\n",
      "[150]\tvalidation_0-error:0.11111\n",
      "[151]\tvalidation_0-error:0.11111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.08417\n",
      "[50]\tvalidation_0-error:0.07407\n",
      "[100]\tvalidation_0-error:0.06734\n",
      "[150]\tvalidation_0-error:0.06397\n",
      "[200]\tvalidation_0-error:0.07407\n",
      "[250]\tvalidation_0-error:0.06734\n",
      "[287]\tvalidation_0-error:0.06734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.13805\n",
      "[50]\tvalidation_0-error:0.08081\n",
      "[100]\tvalidation_0-error:0.08081\n",
      "[150]\tvalidation_0-error:0.08754\n",
      "[158]\tvalidation_0-error:0.08754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.09764\n",
      "[50]\tvalidation_0-error:0.08081\n",
      "[100]\tvalidation_0-error:0.08081\n",
      "[150]\tvalidation_0-error:0.08417\n",
      "[200]\tvalidation_0-error:0.08754\n",
      "[250]\tvalidation_0-error:0.09428\n",
      "[261]\tvalidation_0-error:0.09428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.07744\n",
      "[50]\tvalidation_0-error:0.05724\n",
      "[100]\tvalidation_0-error:0.05724\n",
      "[150]\tvalidation_0-error:0.06061\n",
      "[185]\tvalidation_0-error:0.06061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.11111\n",
      "[50]\tvalidation_0-error:0.07744\n",
      "[100]\tvalidation_0-error:0.08417\n",
      "[150]\tvalidation_0-error:0.08417\n",
      "[151]\tvalidation_0-error:0.08417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.10135\n",
      "[50]\tvalidation_0-error:0.06757\n",
      "[100]\tvalidation_0-error:0.07095\n",
      "[150]\tvalidation_0-error:0.06757\n",
      "[155]\tvalidation_0-error:0.06757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.08108\n",
      "[50]\tvalidation_0-error:0.06419\n",
      "[100]\tvalidation_0-error:0.06419\n",
      "[150]\tvalidation_0-error:0.06081\n",
      "[154]\tvalidation_0-error:0.06081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9289\t = Validation accuracy score\n",
      "\t199.34s\t = Training runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_28\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_458\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(83 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.36262617, Val accuracy: 0.9023569023569024\n",
      "Epoch 10.  Train loss: 0.10407944, Val accuracy: 0.8922558922558923\n",
      "Epoch 20.  Train loss: 0.04580384, Val accuracy: 0.9023569023569024\n",
      "Epoch 30.  Train loss: 0.024105305, Val accuracy: 0.9023569023569024\n",
      "Epoch 40.  Train loss: 0.014250226, Val accuracy: 0.8956228956228957\n",
      "Epoch 50.  Train loss: 0.015713727, Val accuracy: 0.898989898989899\n",
      "Epoch 60.  Train loss: 0.01471065, Val accuracy: 0.9057239057239057\n",
      "Best model found in epoch 43. Val accuracy: 0.9158249158249159\n",
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_458\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(83 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.36830398, Val accuracy: 0.9090909090909091\n",
      "Epoch 10.  Train loss: 0.10955198, Val accuracy: 0.9158249158249159\n",
      "Epoch 20.  Train loss: 0.03692863, Val accuracy: 0.9090909090909091\n",
      "Best model found in epoch 17. Val accuracy: 0.9259259259259259\n",
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_297\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductTitleNL.symbol_count.=\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(86 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.38647032, Val accuracy: 0.8922558922558923\n",
      "Epoch 10.  Train loss: 0.102862656, Val accuracy: 0.9057239057239057\n",
      "Epoch 20.  Train loss: 0.03687268, Val accuracy: 0.8956228956228957\n",
      "Epoch 30.  Train loss: 0.020263292, Val accuracy: 0.898989898989899\n",
      "Best model found in epoch 29. Val accuracy: 0.9124579124579124\n",
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_273\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_690\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_28\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_423\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_539\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(83 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.32991013, Val accuracy: 0.9292929292929293\n",
      "Epoch 10.  Train loss: 0.10290159, Val accuracy: 0.9259259259259259\n",
      "Epoch 20.  Train loss: 0.033969644, Val accuracy: 0.9259259259259259\n",
      "Best model found in epoch 8. Val accuracy: 0.9494949494949495\n",
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_182\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_458\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(81 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.3116096, Val accuracy: 0.9023569023569024\n",
      "Epoch 10.  Train loss: 0.08747369, Val accuracy: 0.9090909090909091\n",
      "Epoch 20.  Train loss: 0.03501895, Val accuracy: 0.9057239057239057\n",
      "Epoch 30.  Train loss: 0.020281585, Val accuracy: 0.9090909090909091\n",
      "Best model found in epoch 12. Val accuracy: 0.9191919191919192\n",
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_690\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_720\",\n",
      "        \"text_722\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(82 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.3851121, Val accuracy: 0.9259259259259259\n",
      "Epoch 10.  Train loss: 0.10339398, Val accuracy: 0.9124579124579124\n",
      "Epoch 20.  Train loss: 0.039681908, Val accuracy: 0.898989898989899\n",
      "Best model found in epoch 0. Val accuracy: 0.9259259259259259\n",
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_273\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(83 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.3868244, Val accuracy: 0.9393939393939394\n",
      "Epoch 10.  Train loss: 0.10663666, Val accuracy: 0.9427609427609428\n",
      "Epoch 20.  Train loss: 0.03959277, Val accuracy: 0.9461279461279462\n",
      "Epoch 30.  Train loss: 0.020360082, Val accuracy: 0.9393939393939394\n",
      "Best model found in epoch 33. Val accuracy: 0.9461279461279462\n",
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(81 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.3671501, Val accuracy: 0.9090909090909091\n",
      "Epoch 10.  Train loss: 0.0965963, Val accuracy: 0.898989898989899\n",
      "Epoch 20.  Train loss: 0.034355458, Val accuracy: 0.898989898989899\n",
      "Epoch 30.  Train loss: 0.021118963, Val accuracy: 0.9124579124579124\n",
      "Best model found in epoch 34. Val accuracy: 0.9158249158249159\n",
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_690\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_28\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_539\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2672 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(85 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.43912944, Val accuracy: 0.918918918918919\n",
      "Epoch 10.  Train loss: 0.11245916, Val accuracy: 0.9256756756756757\n",
      "Epoch 20.  Train loss: 0.039210483, Val accuracy: 0.9087837837837838\n",
      "Best model found in epoch 4. Val accuracy: 0.9324324324324325\n",
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2672 examples, 856 features (849 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 747, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(84 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.60645115, Val accuracy: 0.9121621621621622\n",
      "Epoch 10.  Train loss: 0.12162836, Val accuracy: 0.9324324324324325\n",
      "Epoch 20.  Train loss: 0.045860674, Val accuracy: 0.9290540540540541\n",
      "Best model found in epoch 8. Val accuracy: 0.9358108108108109\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/model.pkl\n",
      "\t0.9279\t = Validation accuracy score\n",
      "\t98.11s\t = Training runtime\n",
      "\t2.7s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00861101\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0942761\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0909091\n",
      "[200]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0909091\n",
      "[250]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00748783\tvalid_set's binary_error: 0.0875421\n",
      "[100]\ttrain_set's binary_error: 0.00636466\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0740741\n",
      "[200]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0740741\n",
      "[250]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0774411\n",
      "[300]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0774411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00748783\tvalid_set's binary_error: 0.114478\n",
      "[100]\ttrain_set's binary_error: 0.00561587\tvalid_set's binary_error: 0.114478\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.107744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00823662\tvalid_set's binary_error: 0.0808081\n",
      "[100]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0707071\n",
      "[200]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0639731\n",
      "[250]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0639731\n",
      "[300]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0707071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00861101\tvalid_set's binary_error: 0.0875421\n",
      "[100]\ttrain_set's binary_error: 0.00673905\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0808081\n",
      "[200]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0808081\n",
      "[250]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0774411\n",
      "[300]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0707071\n",
      "[350]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0740741\n",
      "[400]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00861101\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0.00636466\tvalid_set's binary_error: 0.0875421\n",
      "[150]\ttrain_set's binary_error: 0.00299513\tvalid_set's binary_error: 0.0808081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00786222\tvalid_set's binary_error: 0.0639731\n",
      "[100]\ttrain_set's binary_error: 0.00673905\tvalid_set's binary_error: 0.0639731\n",
      "[150]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0572391\n",
      "[200]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0538721\n",
      "[250]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0505051\n",
      "[300]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0505051\n",
      "[350]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0505051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00711344\tvalid_set's binary_error: 0.10101\n",
      "[100]\ttrain_set's binary_error: 0.00599027\tvalid_set's binary_error: 0.0909091\n",
      "[150]\ttrain_set's binary_error: 0.00524148\tvalid_set's binary_error: 0.0875421\n",
      "[200]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0808081\n",
      "[250]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0774411\n",
      "[300]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0808081\n",
      "[350]\ttrain_set's binary_error: 0.00374392\tvalid_set's binary_error: 0.0841751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00785928\tvalid_set's binary_error: 0.0641892\n",
      "[100]\ttrain_set's binary_error: 0.00673653\tvalid_set's binary_error: 0.0709459\n",
      "[150]\ttrain_set's binary_error: 0.00336826\tvalid_set's binary_error: 0.0743243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00748503\tvalid_set's binary_error: 0.0641892\n",
      "[100]\ttrain_set's binary_error: 0.00636228\tvalid_set's binary_error: 0.0743243\n",
      "[150]\ttrain_set's binary_error: 0.00523952\tvalid_set's binary_error: 0.0777027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9276\t = Validation accuracy score\n",
      "\t805.39s\t = Training runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 6\n",
      "Ensemble size: 44\n",
      "Ensemble weights: \n",
      "[0.97727273 0.         0.         0.         0.02272727 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.9299\t = Validation accuracy score\n",
      "\t1.91s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L2: \t{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L2: \t{'weights': 'distance', 'ag_args': {'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetMXNet_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.tabular_nn_model.TabularNeuralNetModel'>, 'priority': 20}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 13 L2 models ...\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: KNeighborsUnif_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L2/model.pkl\n",
      "\t0.8184\t = Validation accuracy score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L2/model.pkl\n",
      "\t0.8251\t = Validation accuracy score\n",
      "\t0.57s\t = Training runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0396855\tvalid_set's binary_error: 0.0976431\n",
      "[100]\ttrain_set's binary_error: 0.00786222\tvalid_set's binary_error: 0.0909091\n",
      "[150]\ttrain_set's binary_error: 0.00149757\tvalid_set's binary_error: 0.0841751\n",
      "[200]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0841751\n",
      "[250]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0875421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0389367\tvalid_set's binary_error: 0.037037\n",
      "[100]\ttrain_set's binary_error: 0.00673905\tvalid_set's binary_error: 0.043771\n",
      "[150]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.047138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0415575\tvalid_set's binary_error: 0.0673401\n",
      "[100]\ttrain_set's binary_error: 0.00748783\tvalid_set's binary_error: 0.0707071\n",
      "[150]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0572391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0389367\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0.00486709\tvalid_set's binary_error: 0.0909091\n",
      "[150]\ttrain_set's binary_error: 0.00149757\tvalid_set's binary_error: 0.0875421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0400599\tvalid_set's binary_error: 0.0606061\n",
      "[100]\ttrain_set's binary_error: 0.00935979\tvalid_set's binary_error: 0.0673401\n",
      "[150]\ttrain_set's binary_error: 0.00187196\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0400599\tvalid_set's binary_error: 0.0808081\n",
      "[100]\ttrain_set's binary_error: 0.00786222\tvalid_set's binary_error: 0.0841751\n",
      "[150]\ttrain_set's binary_error: 0.00149757\tvalid_set's binary_error: 0.0808081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0393111\tvalid_set's binary_error: 0.0606061\n",
      "[100]\ttrain_set's binary_error: 0.00673905\tvalid_set's binary_error: 0.0707071\n",
      "[150]\ttrain_set's binary_error: 0.00224635\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0370648\tvalid_set's binary_error: 0.0808081\n",
      "[100]\ttrain_set's binary_error: 0.00636466\tvalid_set's binary_error: 0.0875421\n",
      "[150]\ttrain_set's binary_error: 0.00149757\tvalid_set's binary_error: 0.0875421\n",
      "[200]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0841751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0392964\tvalid_set's binary_error: 0.0810811\n",
      "[100]\ttrain_set's binary_error: 0.00711078\tvalid_set's binary_error: 0.0777027\n",
      "[150]\ttrain_set's binary_error: 0.00149701\tvalid_set's binary_error: 0.0777027\n",
      "[200]\ttrain_set's binary_error: 0.00112275\tvalid_set's binary_error: 0.0641892\n",
      "[250]\ttrain_set's binary_error: 0.000748503\tvalid_set's binary_error: 0.0675676\n",
      "[300]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0675676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0415419\tvalid_set's binary_error: 0.0641892\n",
      "[100]\ttrain_set's binary_error: 0.00673653\tvalid_set's binary_error: 0.0608108\n",
      "[150]\ttrain_set's binary_error: 0.00112275\tvalid_set's binary_error: 0.0608108\n",
      "[200]\ttrain_set's binary_error: 0.00112275\tvalid_set's binary_error: 0.0574324\n",
      "[250]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0608108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t0.936\t = Validation accuracy score\n",
      "\t92.48s\t = Training runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0146013\tvalid_set's binary_error: 0.0942761\n",
      "[100]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0909091\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.017222\tvalid_set's binary_error: 0.047138\n",
      "[100]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.043771\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.040404\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.040404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0164732\tvalid_set's binary_error: 0.0707071\n",
      "[100]\ttrain_set's binary_error: 0.000748783\tvalid_set's binary_error: 0.0707071\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0740741\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0707071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0142269\tvalid_set's binary_error: 0.0841751\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0841751\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0841751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0142269\tvalid_set's binary_error: 0.0707071\n",
      "[100]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0740741\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0175964\tvalid_set's binary_error: 0.0808081\n",
      "[100]\ttrain_set's binary_error: 0.000748783\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0160988\tvalid_set's binary_error: 0.0740741\n",
      "[100]\ttrain_set's binary_error: 0.000748783\tvalid_set's binary_error: 0.0740741\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0707071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0153501\tvalid_set's binary_error: 0.0875421\n",
      "[100]\ttrain_set's binary_error: 0.000748783\tvalid_set's binary_error: 0.0740741\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0740741\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0707071\n",
      "[250]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n",
      "[300]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0153443\tvalid_set's binary_error: 0.0641892\n",
      "[100]\ttrain_set's binary_error: 0.00149701\tvalid_set's binary_error: 0.0641892\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.0157186\tvalid_set's binary_error: 0.0675676\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0675676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L2/model.pkl\n",
      "\t0.933\t = Validation accuracy score\n",
      "\t209.89s\t = Training runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L2/model.pkl\n",
      "\t0.9265\t = Validation accuracy score\n",
      "\t3.65s\t = Training runtime\n",
      "\t3.66s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "\t0.9262\t = Validation accuracy score\n",
      "\t3.68s\t = Training runtime\n",
      "\t3.66s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9311119\ttest: 0.9090909\tbest: 0.9090909 (0)\ttotal: 179ms\tremaining: 29m 53s\n",
      "20:\tlearn: 0.9337327\ttest: 0.9057239\tbest: 0.9090909 (0)\ttotal: 2.85s\tremaining: 22m 37s\n",
      "40:\tlearn: 0.9329839\ttest: 0.9057239\tbest: 0.9090909 (0)\ttotal: 5.46s\tremaining: 22m 6s\n",
      "60:\tlearn: 0.9341071\ttest: 0.9057239\tbest: 0.9090909 (0)\ttotal: 8.14s\tremaining: 22m 6s\n",
      "80:\tlearn: 0.9359790\ttest: 0.9124579\tbest: 0.9124579 (70)\ttotal: 10.9s\tremaining: 22m 15s\n",
      "100:\tlearn: 0.9367278\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 13.7s\tremaining: 22m 20s\n",
      "120:\tlearn: 0.9385998\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 16.3s\tremaining: 22m 13s\n",
      "140:\tlearn: 0.9393486\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 19s\tremaining: 22m 6s\n",
      "160:\tlearn: 0.9393486\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 21.6s\tremaining: 21m 57s\n",
      "180:\tlearn: 0.9412205\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 24.1s\tremaining: 21m 45s\n",
      "200:\tlearn: 0.9419693\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 26.5s\tremaining: 21m 33s\n",
      "220:\tlearn: 0.9419693\ttest: 0.9090909\tbest: 0.9124579 (70)\ttotal: 29s\tremaining: 21m 24s\n",
      "bestTest = 0.9124579125\n",
      "bestIteration = 70\n",
      "Shrink model to first 71 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9086484\ttest: 0.9427609\tbest: 0.9427609 (0)\ttotal: 136ms\tremaining: 22m 38s\n",
      "20:\tlearn: 0.9284912\ttest: 0.9629630\tbest: 0.9663300 (7)\ttotal: 2.59s\tremaining: 20m 30s\n",
      "40:\tlearn: 0.9296144\ttest: 0.9663300\tbest: 0.9663300 (7)\ttotal: 5.01s\tremaining: 20m 16s\n",
      "60:\tlearn: 0.9311119\ttest: 0.9663300\tbest: 0.9663300 (7)\ttotal: 7.72s\tremaining: 20m 58s\n",
      "80:\tlearn: 0.9318607\ttest: 0.9629630\tbest: 0.9663300 (7)\ttotal: 10.4s\tremaining: 21m 17s\n",
      "100:\tlearn: 0.9318607\ttest: 0.9629630\tbest: 0.9663300 (7)\ttotal: 13s\tremaining: 21m 15s\n",
      "120:\tlearn: 0.9322351\ttest: 0.9629630\tbest: 0.9663300 (7)\ttotal: 15.6s\tremaining: 21m 13s\n",
      "140:\tlearn: 0.9329839\ttest: 0.9629630\tbest: 0.9663300 (7)\ttotal: 18.3s\tremaining: 21m 16s\n",
      "bestTest = 0.9663299663\n",
      "bestIteration = 7\n",
      "Shrink model to first 8 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9273680\ttest: 0.9191919\tbest: 0.9191919 (0)\ttotal: 126ms\tremaining: 20m 58s\n",
      "20:\tlearn: 0.9329839\ttest: 0.9393939\tbest: 0.9393939 (8)\ttotal: 2.48s\tremaining: 19m 37s\n",
      "40:\tlearn: 0.9333583\ttest: 0.9393939\tbest: 0.9393939 (8)\ttotal: 5.03s\tremaining: 20m 22s\n",
      "60:\tlearn: 0.9337327\ttest: 0.9360269\tbest: 0.9393939 (8)\ttotal: 7.73s\tremaining: 20m 59s\n",
      "80:\tlearn: 0.9344815\ttest: 0.9393939\tbest: 0.9393939 (8)\ttotal: 10.4s\tremaining: 21m 10s\n",
      "100:\tlearn: 0.9352303\ttest: 0.9393939\tbest: 0.9393939 (8)\ttotal: 13s\tremaining: 21m 9s\n",
      "120:\tlearn: 0.9352303\ttest: 0.9393939\tbest: 0.9393939 (8)\ttotal: 15.5s\tremaining: 21m 7s\n",
      "140:\tlearn: 0.9359790\ttest: 0.9393939\tbest: 0.9393939 (8)\ttotal: 18.1s\tremaining: 21m 4s\n",
      "bestTest = 0.9393939394\n",
      "bestIteration = 8\n",
      "Shrink model to first 9 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9296144\ttest: 0.9124579\tbest: 0.9124579 (0)\ttotal: 95.6ms\tremaining: 15m 55s\n",
      "20:\tlearn: 0.9333583\ttest: 0.9124579\tbest: 0.9191919 (2)\ttotal: 2.37s\tremaining: 18m 44s\n",
      "40:\tlearn: 0.9341071\ttest: 0.9090909\tbest: 0.9191919 (2)\ttotal: 4.76s\tremaining: 19m 15s\n",
      "60:\tlearn: 0.9371022\ttest: 0.9090909\tbest: 0.9191919 (2)\ttotal: 7.52s\tremaining: 20m 25s\n",
      "80:\tlearn: 0.9378510\ttest: 0.9090909\tbest: 0.9191919 (2)\ttotal: 10.2s\tremaining: 20m 53s\n",
      "100:\tlearn: 0.9371022\ttest: 0.9124579\tbest: 0.9191919 (2)\ttotal: 12.9s\tremaining: 21m 7s\n",
      "120:\tlearn: 0.9374766\ttest: 0.9124579\tbest: 0.9191919 (2)\ttotal: 15.6s\tremaining: 21m 14s\n",
      "140:\tlearn: 0.9378510\ttest: 0.9124579\tbest: 0.9191919 (2)\ttotal: 18.3s\tremaining: 21m 16s\n",
      "bestTest = 0.9191919192\n",
      "bestIteration = 2\n",
      "Shrink model to first 3 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9292400\ttest: 0.9259259\tbest: 0.9259259 (0)\ttotal: 126ms\tremaining: 21m 2s\n",
      "20:\tlearn: 0.9322351\ttest: 0.9292929\tbest: 0.9360269 (9)\ttotal: 2.52s\tremaining: 19m 57s\n",
      "40:\tlearn: 0.9318607\ttest: 0.9259259\tbest: 0.9360269 (9)\ttotal: 5.13s\tremaining: 20m 45s\n",
      "60:\tlearn: 0.9333583\ttest: 0.9292929\tbest: 0.9360269 (9)\ttotal: 7.94s\tremaining: 21m 34s\n",
      "80:\tlearn: 0.9337327\ttest: 0.9225589\tbest: 0.9360269 (9)\ttotal: 10.7s\tremaining: 21m 50s\n",
      "100:\tlearn: 0.9356046\ttest: 0.9225589\tbest: 0.9360269 (9)\ttotal: 13.5s\tremaining: 22m 3s\n",
      "120:\tlearn: 0.9359790\ttest: 0.9225589\tbest: 0.9360269 (9)\ttotal: 16.4s\tremaining: 22m 16s\n",
      "140:\tlearn: 0.9359790\ttest: 0.9225589\tbest: 0.9360269 (9)\ttotal: 19s\tremaining: 22m 10s\n",
      "bestTest = 0.936026936\n",
      "bestIteration = 9\n",
      "Shrink model to first 10 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9266192\ttest: 0.9292929\tbest: 0.9292929 (0)\ttotal: 102ms\tremaining: 17m 3s\n",
      "20:\tlearn: 0.9326095\ttest: 0.9292929\tbest: 0.9393939 (2)\ttotal: 2.44s\tremaining: 19m 21s\n",
      "40:\tlearn: 0.9329839\ttest: 0.9259259\tbest: 0.9393939 (2)\ttotal: 5.04s\tremaining: 20m 24s\n",
      "60:\tlearn: 0.9326095\ttest: 0.9259259\tbest: 0.9393939 (2)\ttotal: 7.69s\tremaining: 20m 52s\n",
      "80:\tlearn: 0.9333583\ttest: 0.9259259\tbest: 0.9393939 (2)\ttotal: 10.4s\tremaining: 21m 8s\n",
      "100:\tlearn: 0.9359790\ttest: 0.9259259\tbest: 0.9393939 (2)\ttotal: 13.1s\tremaining: 21m 19s\n",
      "120:\tlearn: 0.9374766\ttest: 0.9225589\tbest: 0.9393939 (2)\ttotal: 15.7s\tremaining: 21m 19s\n",
      "140:\tlearn: 0.9378510\ttest: 0.9225589\tbest: 0.9393939 (2)\ttotal: 18.3s\tremaining: 21m 19s\n",
      "bestTest = 0.9393939394\n",
      "bestIteration = 2\n",
      "Shrink model to first 3 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9281168\ttest: 0.9259259\tbest: 0.9259259 (0)\ttotal: 129ms\tremaining: 21m 32s\n",
      "20:\tlearn: 0.9333583\ttest: 0.9360269\tbest: 0.9360269 (4)\ttotal: 2.48s\tremaining: 19m 39s\n",
      "40:\tlearn: 0.9337327\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 4.89s\tremaining: 19m 47s\n",
      "60:\tlearn: 0.9341071\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 7.51s\tremaining: 20m 24s\n",
      "80:\tlearn: 0.9356046\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 10.2s\tremaining: 20m 47s\n",
      "100:\tlearn: 0.9367278\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 12.9s\tremaining: 21m 1s\n",
      "120:\tlearn: 0.9374766\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 15.5s\tremaining: 21m 8s\n",
      "140:\tlearn: 0.9382254\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 18s\tremaining: 20m 59s\n",
      "160:\tlearn: 0.9393486\ttest: 0.9393939\tbest: 0.9393939 (29)\ttotal: 20.5s\tremaining: 20m 50s\n",
      "bestTest = 0.9393939394\n",
      "bestIteration = 29\n",
      "Shrink model to first 30 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9108948\ttest: 0.9057239\tbest: 0.9057239 (0)\ttotal: 132ms\tremaining: 22m 4s\n",
      "20:\tlearn: 0.9322351\ttest: 0.9191919\tbest: 0.9259259 (3)\ttotal: 2.39s\tremaining: 18m 56s\n",
      "40:\tlearn: 0.9359790\ttest: 0.9158249\tbest: 0.9259259 (3)\ttotal: 4.96s\tremaining: 20m 4s\n",
      "60:\tlearn: 0.9363534\ttest: 0.9158249\tbest: 0.9259259 (3)\ttotal: 7.69s\tremaining: 20m 53s\n",
      "80:\tlearn: 0.9371022\ttest: 0.9158249\tbest: 0.9259259 (3)\ttotal: 10.4s\tremaining: 21m 15s\n",
      "100:\tlearn: 0.9382254\ttest: 0.9158249\tbest: 0.9259259 (3)\ttotal: 13.1s\tremaining: 21m 27s\n",
      "120:\tlearn: 0.9385998\ttest: 0.9158249\tbest: 0.9259259 (3)\ttotal: 15.9s\tremaining: 21m 35s\n",
      "140:\tlearn: 0.9397230\ttest: 0.9158249\tbest: 0.9259259 (3)\ttotal: 18.6s\tremaining: 21m 39s\n",
      "bestTest = 0.9259259259\n",
      "bestIteration = 3\n",
      "Shrink model to first 4 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9270210\ttest: 0.9222973\tbest: 0.9222973 (0)\ttotal: 124ms\tremaining: 20m 42s\n",
      "20:\tlearn: 0.9300150\ttest: 0.9358108\tbest: 0.9391892 (5)\ttotal: 2.4s\tremaining: 18m 59s\n",
      "40:\tlearn: 0.9307635\ttest: 0.9358108\tbest: 0.9391892 (5)\ttotal: 5.01s\tremaining: 20m 16s\n",
      "60:\tlearn: 0.9330090\ttest: 0.9391892\tbest: 0.9391892 (5)\ttotal: 7.58s\tremaining: 20m 34s\n",
      "80:\tlearn: 0.9341317\ttest: 0.9391892\tbest: 0.9391892 (5)\ttotal: 10.2s\tremaining: 20m 44s\n",
      "100:\tlearn: 0.9345060\ttest: 0.9391892\tbest: 0.9391892 (5)\ttotal: 12.8s\tremaining: 20m 59s\n",
      "120:\tlearn: 0.9352545\ttest: 0.9391892\tbest: 0.9391892 (5)\ttotal: 15.5s\tremaining: 21m 1s\n",
      "140:\tlearn: 0.9367515\ttest: 0.9391892\tbest: 0.9391892 (5)\ttotal: 18.2s\tremaining: 21m 13s\n",
      "bestTest = 0.9391891892\n",
      "bestIteration = 5\n",
      "Shrink model to first 6 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'task_type': 'GPU'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9262725\ttest: 0.9358108\tbest: 0.9358108 (0)\ttotal: 118ms\tremaining: 19m 37s\n",
      "20:\tlearn: 0.9303892\ttest: 0.9324324\tbest: 0.9425676 (3)\ttotal: 2.38s\tremaining: 18m 49s\n",
      "40:\tlearn: 0.9311377\ttest: 0.9358108\tbest: 0.9425676 (3)\ttotal: 4.96s\tremaining: 20m 5s\n",
      "60:\tlearn: 0.9318862\ttest: 0.9358108\tbest: 0.9425676 (3)\ttotal: 7.72s\tremaining: 20m 57s\n",
      "80:\tlearn: 0.9326347\ttest: 0.9358108\tbest: 0.9425676 (3)\ttotal: 10.4s\tremaining: 21m 16s\n",
      "100:\tlearn: 0.9318862\ttest: 0.9358108\tbest: 0.9425676 (3)\ttotal: 13s\tremaining: 21m 15s\n",
      "120:\tlearn: 0.9341317\ttest: 0.9358108\tbest: 0.9425676 (3)\ttotal: 15.8s\tremaining: 21m 26s\n",
      "140:\tlearn: 0.9345060\ttest: 0.9358108\tbest: 0.9425676 (3)\ttotal: 18.3s\tremaining: 21m 16s\n",
      "bestTest = 0.9425675676\n",
      "bestIteration = 3\n",
      "Shrink model to first 4 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L2/model.pkl\n",
      "\t0.936\t = Validation accuracy score\n",
      "\t239.93s\t = Training runtime\n",
      "\t2.89s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "\t0.9249\t = Validation accuracy score\n",
      "\t2.49s\t = Training runtime\n",
      "\t3.75s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "\t0.9222\t = Validation accuracy score\n",
      "\t2.25s\t = Training runtime\n",
      "\t3.68s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.8989899158477783.\n",
      "Better model found at epoch 2 with accuracy value: 0.9158248901367188.\n",
      "Better model found at epoch 17 with accuracy value: 0.9191918969154358.\n",
      "Model validation metrics: 0.9191918969154358\n",
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9562289714813232.\n",
      "No improvement since epoch 0: early stopping\n",
      "Model validation metrics: 0.9562289714813232\n",
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.932659924030304.\n",
      "Better model found at epoch 1 with accuracy value: 0.939393937587738.\n",
      "No improvement since epoch 1: early stopping\n",
      "Model validation metrics: 0.939393937587738\n",
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.9124578833580017.\n",
      "No improvement since epoch 0: early stopping\n",
      "Model validation metrics: 0.9124578833580017\n",
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9124578833580017.\n",
      "No improvement since epoch 0: early stopping\n",
      "Model validation metrics: 0.9124578833580017\n",
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9090909361839294.\n",
      "Better model found at epoch 1 with accuracy value: 0.9124578833580017.\n",
      "Better model found at epoch 15 with accuracy value: 0.9191918969154358.\n",
      "Better model found at epoch 20 with accuracy value: 0.9225589036941528.\n",
      "Model validation metrics: 0.9225589036941528\n",
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9191918969154358.\n",
      "Better model found at epoch 1 with accuracy value: 0.9225589036941528.\n",
      "No improvement since epoch 1: early stopping\n",
      "Model validation metrics: 0.9225589036941528\n",
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.8989899158477783.\n",
      "Better model found at epoch 10 with accuracy value: 0.9023569226264954.\n",
      "Model validation metrics: 0.9023569226264954\n",
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.9087837934494019.\n",
      "Better model found at epoch 1 with accuracy value: 0.9222972989082336.\n",
      "Better model found at epoch 2 with accuracy value: 0.9290540814399719.\n",
      "No improvement since epoch 2: early stopping\n",
      "Model validation metrics: 0.9290540814399719\n",
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 16/16 categorical features\n",
      "Using 3121 cont features\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(2863, 138)\n",
      "    (1): Embedding(2616, 131)\n",
      "    (2): Embedding(12, 6)\n",
      "    (3): Embedding(13, 7)\n",
      "    (4): Embedding(706, 63)\n",
      "    (5): Embedding(370, 44)\n",
      "    (6): Embedding(87, 20)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(5, 4)\n",
      "    (9): Embedding(5, 4)\n",
      "    (10): Embedding(5, 4)\n",
      "    (11): Embedding(5, 4)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(5, 4)\n",
      "    (14): Embedding(5, 4)\n",
      "    (15): Embedding(2767, 135)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(3121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=3697, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with accuracy value: 0.9189189076423645.\n",
      "Better model found at epoch 2 with accuracy value: 0.9324324131011963.\n",
      "Better model found at epoch 13 with accuracy value: 0.9358108043670654.\n",
      "Model validation metrics: 0.9358108043670654\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t0.9252\t = Validation accuracy score\n",
      "\t224.26s\t = Training runtime\n",
      "\t17.3s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.11785\n",
      "[50]\tvalidation_0-error:0.09428\n",
      "[100]\tvalidation_0-error:0.09428\n",
      "[150]\tvalidation_0-error:0.09091\n",
      "[200]\tvalidation_0-error:0.09091\n",
      "[206]\tvalidation_0-error:0.09091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.06397\n",
      "[50]\tvalidation_0-error:0.05387\n",
      "[100]\tvalidation_0-error:0.05387\n",
      "[150]\tvalidation_0-error:0.04714\n",
      "[161]\tvalidation_0-error:0.04714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.08417\n",
      "[50]\tvalidation_0-error:0.06734\n",
      "[100]\tvalidation_0-error:0.06734\n",
      "[150]\tvalidation_0-error:0.06397\n",
      "[193]\tvalidation_0-error:0.06061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.10774\n",
      "[50]\tvalidation_0-error:0.08081\n",
      "[100]\tvalidation_0-error:0.08417\n",
      "[150]\tvalidation_0-error:0.08417\n",
      "[197]\tvalidation_0-error:0.08081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.09091\n",
      "[50]\tvalidation_0-error:0.08081\n",
      "[100]\tvalidation_0-error:0.07407\n",
      "[150]\tvalidation_0-error:0.07744\n",
      "[200]\tvalidation_0-error:0.08081\n",
      "[246]\tvalidation_0-error:0.07744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.10438\n",
      "[50]\tvalidation_0-error:0.07407\n",
      "[100]\tvalidation_0-error:0.07071\n",
      "[150]\tvalidation_0-error:0.07071\n",
      "[200]\tvalidation_0-error:0.06734\n",
      "[226]\tvalidation_0-error:0.07071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.08081\n",
      "[50]\tvalidation_0-error:0.07071\n",
      "[100]\tvalidation_0-error:0.06397\n",
      "[150]\tvalidation_0-error:0.07071\n",
      "[200]\tvalidation_0-error:0.07071\n",
      "[235]\tvalidation_0-error:0.07071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.12121\n",
      "[50]\tvalidation_0-error:0.08081\n",
      "[100]\tvalidation_0-error:0.08081\n",
      "[150]\tvalidation_0-error:0.08081\n",
      "[200]\tvalidation_0-error:0.07744\n",
      "[214]\tvalidation_0-error:0.07744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.10473\n",
      "[50]\tvalidation_0-error:0.06757\n",
      "[100]\tvalidation_0-error:0.06419\n",
      "[150]\tvalidation_0-error:0.06757\n",
      "[179]\tvalidation_0-error:0.06757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.07432\n",
      "[50]\tvalidation_0-error:0.06419\n",
      "[100]\tvalidation_0-error:0.06757\n",
      "[150]\tvalidation_0-error:0.06419\n",
      "[168]\tvalidation_0-error:0.06419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L2/model.pkl\n",
      "\t0.9326\t = Validation accuracy score\n",
      "\t220.44s\t = Training runtime\n",
      "\t1.19s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_28\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_458\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(82 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.36309633, Val accuracy: 0.8922558922558923\n",
      "Epoch 10.  Train loss: 0.099400565, Val accuracy: 0.9057239057239057\n",
      "Epoch 20.  Train loss: 0.034972586, Val accuracy: 0.9124579124579124\n",
      "Epoch 30.  Train loss: 0.025331527, Val accuracy: 0.9124579124579124\n",
      "Epoch 40.  Train loss: 0.013212554, Val accuracy: 0.9023569023569024\n",
      "Best model found in epoch 28. Val accuracy: 0.9225589225589226\n",
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(84 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.4810838, Val accuracy: 0.936026936026936\n",
      "Epoch 10.  Train loss: 0.112588786, Val accuracy: 0.9528619528619529\n",
      "Epoch 20.  Train loss: 0.036758658, Val accuracy: 0.9494949494949495\n",
      "Best model found in epoch 4. Val accuracy: 0.9562289562289562\n",
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_208\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(84 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.46841675, Val accuracy: 0.9259259259259259\n",
      "Epoch 10.  Train loss: 0.12086989, Val accuracy: 0.9259259259259259\n",
      "Epoch 20.  Train loss: 0.04552433, Val accuracy: 0.9158249158249159\n",
      "Epoch 30.  Train loss: 0.019815259, Val accuracy: 0.9124579124579124\n",
      "Best model found in epoch 13. Val accuracy: 0.936026936026936\n",
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(84 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.5885745, Val accuracy: 0.9225589225589226\n",
      "Epoch 10.  Train loss: 0.12149081, Val accuracy: 0.9158249158249159\n",
      "Epoch 20.  Train loss: 0.043143045, Val accuracy: 0.9090909090909091\n",
      "Best model found in epoch 9. Val accuracy: 0.9225589225589226\n",
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_690\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_423\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(85 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.4572007, Val accuracy: 0.9124579124579124\n",
      "Epoch 10.  Train loss: 0.11147583, Val accuracy: 0.9225589225589226\n",
      "Epoch 20.  Train loss: 0.040119976, Val accuracy: 0.9158249158249159\n",
      "Epoch 30.  Train loss: 0.026712421, Val accuracy: 0.9023569023569024\n",
      "Best model found in epoch 13. Val accuracy: 0.9259259259259259\n",
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_182\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_208\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_297\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_554\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_690\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_184\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(81 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.29386207, Val accuracy: 0.9158249158249159\n",
      "Epoch 10.  Train loss: 0.08056424, Val accuracy: 0.9090909090909091\n",
      "Epoch 20.  Train loss: 0.031307932, Val accuracy: 0.9057239057239057\n",
      "Epoch 30.  Train loss: 0.015012724, Val accuracy: 0.9191919191919192\n",
      "Epoch 40.  Train loss: 0.018735627, Val accuracy: 0.9023569023569024\n",
      "Best model found in epoch 26. Val accuracy: 0.9259259259259259\n",
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_423\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(83 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.38412502, Val accuracy: 0.9191919191919192\n",
      "Epoch 10.  Train loss: 0.10602492, Val accuracy: 0.9225589225589226\n",
      "Epoch 20.  Train loss: 0.035989735, Val accuracy: 0.9292929292929293\n",
      "Epoch 30.  Train loss: 0.019818604, Val accuracy: 0.9292929292929293\n",
      "Best model found in epoch 35. Val accuracy: 0.9326599326599326\n",
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_193\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_297\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_690\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_28\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_273\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2671 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(84 -> 19, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.48216078, Val accuracy: 0.898989898989899\n",
      "Epoch 10.  Train loss: 0.11194006, Val accuracy: 0.9090909090909091\n",
      "Epoch 20.  Train loss: 0.04342029, Val accuracy: 0.9023569023569024\n",
      "Epoch 30.  Train loss: 0.02120619, Val accuracy: 0.9023569023569024\n",
      "Best model found in epoch 9. Val accuracy: 0.9158249158249159\n",
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_28\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_208\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_273\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_155\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_458\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_539\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_count.=\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2672 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(82 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.59852344, Val accuracy: 0.9155405405405406\n",
      "Epoch 10.  Train loss: 0.129006, Val accuracy: 0.9087837837837838\n",
      "Epoch 20.  Train loss: 0.04119515, Val accuracy: 0.9222972972972973\n",
      "Epoch 30.  Train loss: 0.019210385, Val accuracy: 0.9222972972972973\n",
      "Epoch 40.  Train loss: 0.017191272, Val accuracy: 0.9256756756756757\n",
      "Epoch 50.  Train loss: 0.014774, Val accuracy: 0.9290540540540541\n",
      "Epoch 60.  Train loss: 0.009590077, Val accuracy: 0.9121621621621622\n",
      "Epoch 70.  Train loss: 0.009997889, Val accuracy: 0.918918918918919\n",
      "Best model found in epoch 56. Val accuracy: 0.9459459459459459\n",
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "AutoGluon Neural Network infers features are of the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"KNeighborsUnif_BAG_L1\",\n",
      "        \"KNeighborsDist_BAG_L1\",\n",
      "        \"LightGBMXT_BAG_L1\",\n",
      "        \"LightGBM_BAG_L1\",\n",
      "        \"RandomForestGini_BAG_L1\",\n",
      "        \"RandomForestEntr_BAG_L1\",\n",
      "        \"CatBoost_BAG_L1\",\n",
      "        \"ExtraTreesGini_BAG_L1\",\n",
      "        \"ExtraTreesEntr_BAG_L1\",\n",
      "        \"NeuralNetFastAI_BAG_L1\",\n",
      "        \"XGBoost_BAG_L1\",\n",
      "        \"NeuralNetMXNet_BAG_L1\",\n",
      "        \"LightGBMLarge_BAG_L1\",\n",
      "        \"text_0\",\n",
      "        \"text_2\",\n",
      "        \"text_3\",\n",
      "        \"text_4\",\n",
      "        \"text_5\",\n",
      "        \"text_6\",\n",
      "        \"text_7\",\n",
      "        \"text_8\",\n",
      "        \"text_9\",\n",
      "        \"text_10\",\n",
      "        \"text_11\",\n",
      "        \"text_12\",\n",
      "        \"text_13\",\n",
      "        \"text_14\",\n",
      "        \"text_15\",\n",
      "        \"text_16\",\n",
      "        \"text_17\",\n",
      "        \"text_18\",\n",
      "        \"text_19\",\n",
      "        \"text_20\",\n",
      "        \"text_23\",\n",
      "        \"text_24\",\n",
      "        \"text_26\",\n",
      "        \"text_29\",\n",
      "        \"text_30\",\n",
      "        \"text_31\",\n",
      "        \"text_32\",\n",
      "        \"text_33\",\n",
      "        \"text_34\",\n",
      "        \"text_35\",\n",
      "        \"text_36\",\n",
      "        \"text_37\",\n",
      "        \"text_38\",\n",
      "        \"text_39\",\n",
      "        \"text_40\",\n",
      "        \"text_41\",\n",
      "        \"text_42\",\n",
      "        \"text_43\",\n",
      "        \"text_44\",\n",
      "        \"text_45\",\n",
      "        \"text_46\",\n",
      "        \"text_47\",\n",
      "        \"text_48\",\n",
      "        \"text_49\",\n",
      "        \"text_50\",\n",
      "        \"text_51\",\n",
      "        \"text_52\",\n",
      "        \"text_53\",\n",
      "        \"text_54\",\n",
      "        \"text_55\",\n",
      "        \"text_56\",\n",
      "        \"text_57\",\n",
      "        \"text_58\",\n",
      "        \"text_59\",\n",
      "        \"text_60\",\n",
      "        \"text_61\",\n",
      "        \"text_62\",\n",
      "        \"text_63\",\n",
      "        \"text_64\",\n",
      "        \"text_65\",\n",
      "        \"text_66\",\n",
      "        \"text_67\",\n",
      "        \"text_68\",\n",
      "        \"text_69\",\n",
      "        \"text_70\",\n",
      "        \"text_71\",\n",
      "        \"text_72\",\n",
      "        \"text_73\",\n",
      "        \"text_74\",\n",
      "        \"text_75\",\n",
      "        \"text_76\",\n",
      "        \"text_77\",\n",
      "        \"text_78\",\n",
      "        \"text_79\",\n",
      "        \"text_80\",\n",
      "        \"text_81\",\n",
      "        \"text_83\",\n",
      "        \"text_84\",\n",
      "        \"text_85\",\n",
      "        \"text_86\",\n",
      "        \"text_87\",\n",
      "        \"text_88\",\n",
      "        \"text_89\",\n",
      "        \"text_91\",\n",
      "        \"text_92\",\n",
      "        \"text_93\",\n",
      "        \"text_94\",\n",
      "        \"text_95\",\n",
      "        \"text_96\",\n",
      "        \"text_97\",\n",
      "        \"text_98\",\n",
      "        \"text_99\",\n",
      "        \"text_100\",\n",
      "        \"text_101\",\n",
      "        \"text_102\",\n",
      "        \"text_103\",\n",
      "        \"text_104\",\n",
      "        \"text_105\",\n",
      "        \"text_106\",\n",
      "        \"text_107\",\n",
      "        \"text_108\",\n",
      "        \"text_109\",\n",
      "        \"text_110\",\n",
      "        \"text_111\",\n",
      "        \"text_112\",\n",
      "        \"text_113\",\n",
      "        \"text_114\",\n",
      "        \"text_115\",\n",
      "        \"text_116\",\n",
      "        \"text_117\",\n",
      "        \"text_118\",\n",
      "        \"text_119\",\n",
      "        \"text_120\",\n",
      "        \"text_121\",\n",
      "        \"text_122\",\n",
      "        \"text_123\",\n",
      "        \"text_124\",\n",
      "        \"text_125\",\n",
      "        \"text_126\",\n",
      "        \"text_127\",\n",
      "        \"text_128\",\n",
      "        \"text_129\",\n",
      "        \"text_130\",\n",
      "        \"text_131\",\n",
      "        \"text_132\",\n",
      "        \"text_133\",\n",
      "        \"text_134\",\n",
      "        \"text_135\",\n",
      "        \"text_136\",\n",
      "        \"text_137\",\n",
      "        \"text_138\",\n",
      "        \"text_139\",\n",
      "        \"text_140\",\n",
      "        \"text_141\",\n",
      "        \"text_142\",\n",
      "        \"text_143\",\n",
      "        \"text_144\",\n",
      "        \"text_145\",\n",
      "        \"text_146\",\n",
      "        \"text_147\",\n",
      "        \"text_148\",\n",
      "        \"text_149\",\n",
      "        \"text_150\",\n",
      "        \"text_151\",\n",
      "        \"text_152\",\n",
      "        \"text_153\",\n",
      "        \"text_154\",\n",
      "        \"text_155\",\n",
      "        \"text_156\",\n",
      "        \"text_157\",\n",
      "        \"text_158\",\n",
      "        \"text_159\",\n",
      "        \"text_160\",\n",
      "        \"text_161\",\n",
      "        \"text_162\",\n",
      "        \"text_164\",\n",
      "        \"text_165\",\n",
      "        \"text_166\",\n",
      "        \"text_167\",\n",
      "        \"text_168\",\n",
      "        \"text_169\",\n",
      "        \"text_170\",\n",
      "        \"text_171\",\n",
      "        \"text_172\",\n",
      "        \"text_173\",\n",
      "        \"text_174\",\n",
      "        \"text_175\",\n",
      "        \"text_176\",\n",
      "        \"text_177\",\n",
      "        \"text_178\",\n",
      "        \"text_179\",\n",
      "        \"text_180\",\n",
      "        \"text_181\",\n",
      "        \"text_183\",\n",
      "        \"text_185\",\n",
      "        \"text_186\",\n",
      "        \"text_187\",\n",
      "        \"text_188\",\n",
      "        \"text_189\",\n",
      "        \"text_190\",\n",
      "        \"text_191\",\n",
      "        \"text_192\",\n",
      "        \"text_194\",\n",
      "        \"text_195\",\n",
      "        \"text_196\",\n",
      "        \"text_197\",\n",
      "        \"text_198\",\n",
      "        \"text_199\",\n",
      "        \"text_200\",\n",
      "        \"text_201\",\n",
      "        \"text_202\",\n",
      "        \"text_203\",\n",
      "        \"text_204\",\n",
      "        \"text_205\",\n",
      "        \"text_206\",\n",
      "        \"text_207\",\n",
      "        \"text_209\",\n",
      "        \"text_212\",\n",
      "        \"text_213\",\n",
      "        \"text_214\",\n",
      "        \"text_215\",\n",
      "        \"text_216\",\n",
      "        \"text_218\",\n",
      "        \"text_219\",\n",
      "        \"text_220\",\n",
      "        \"text_221\",\n",
      "        \"text_222\",\n",
      "        \"text_223\",\n",
      "        \"text_225\",\n",
      "        \"text_226\",\n",
      "        \"text_227\",\n",
      "        \"text_228\",\n",
      "        \"text_230\",\n",
      "        \"text_231\",\n",
      "        \"text_232\",\n",
      "        \"text_233\",\n",
      "        \"text_234\",\n",
      "        \"text_235\",\n",
      "        \"text_236\",\n",
      "        \"text_237\",\n",
      "        \"text_238\",\n",
      "        \"text_239\",\n",
      "        \"text_241\",\n",
      "        \"text_242\",\n",
      "        \"text_243\",\n",
      "        \"text_244\",\n",
      "        \"text_245\",\n",
      "        \"text_246\",\n",
      "        \"text_247\",\n",
      "        \"text_248\",\n",
      "        \"text_249\",\n",
      "        \"text_250\",\n",
      "        \"text_251\",\n",
      "        \"text_252\",\n",
      "        \"text_253\",\n",
      "        \"text_254\",\n",
      "        \"text_255\",\n",
      "        \"text_256\",\n",
      "        \"text_257\",\n",
      "        \"text_258\",\n",
      "        \"text_259\",\n",
      "        \"text_260\",\n",
      "        \"text_261\",\n",
      "        \"text_262\",\n",
      "        \"text_263\",\n",
      "        \"text_264\",\n",
      "        \"text_266\",\n",
      "        \"text_267\",\n",
      "        \"text_268\",\n",
      "        \"text_269\",\n",
      "        \"text_271\",\n",
      "        \"text_272\",\n",
      "        \"text_273\",\n",
      "        \"text_275\",\n",
      "        \"text_276\",\n",
      "        \"text_277\",\n",
      "        \"text_278\",\n",
      "        \"text_279\",\n",
      "        \"text_280\",\n",
      "        \"text_282\",\n",
      "        \"text_283\",\n",
      "        \"text_284\",\n",
      "        \"text_285\",\n",
      "        \"text_286\",\n",
      "        \"text_287\",\n",
      "        \"text_288\",\n",
      "        \"text_290\",\n",
      "        \"text_291\",\n",
      "        \"text_293\",\n",
      "        \"text_294\",\n",
      "        \"text_295\",\n",
      "        \"text_296\",\n",
      "        \"text_298\",\n",
      "        \"text_299\",\n",
      "        \"text_300\",\n",
      "        \"text_301\",\n",
      "        \"text_302\",\n",
      "        \"text_303\",\n",
      "        \"text_304\",\n",
      "        \"text_305\",\n",
      "        \"text_307\",\n",
      "        \"text_308\",\n",
      "        \"text_309\",\n",
      "        \"text_310\",\n",
      "        \"text_311\",\n",
      "        \"text_312\",\n",
      "        \"text_313\",\n",
      "        \"text_314\",\n",
      "        \"text_315\",\n",
      "        \"text_316\",\n",
      "        \"text_317\",\n",
      "        \"text_318\",\n",
      "        \"text_320\",\n",
      "        \"text_321\",\n",
      "        \"text_322\",\n",
      "        \"text_323\",\n",
      "        \"text_324\",\n",
      "        \"text_325\",\n",
      "        \"text_326\",\n",
      "        \"text_327\",\n",
      "        \"text_328\",\n",
      "        \"text_329\",\n",
      "        \"text_330\",\n",
      "        \"text_331\",\n",
      "        \"text_332\",\n",
      "        \"text_333\",\n",
      "        \"text_334\",\n",
      "        \"text_335\",\n",
      "        \"text_336\",\n",
      "        \"text_337\",\n",
      "        \"text_338\",\n",
      "        \"text_339\",\n",
      "        \"text_341\",\n",
      "        \"text_342\",\n",
      "        \"text_343\",\n",
      "        \"text_344\",\n",
      "        \"text_345\",\n",
      "        \"text_346\",\n",
      "        \"text_347\",\n",
      "        \"text_348\",\n",
      "        \"text_349\",\n",
      "        \"text_350\",\n",
      "        \"text_351\",\n",
      "        \"text_352\",\n",
      "        \"text_353\",\n",
      "        \"text_354\",\n",
      "        \"text_355\",\n",
      "        \"text_356\",\n",
      "        \"text_357\",\n",
      "        \"text_358\",\n",
      "        \"text_359\",\n",
      "        \"text_360\",\n",
      "        \"text_361\",\n",
      "        \"text_362\",\n",
      "        \"text_363\",\n",
      "        \"text_364\",\n",
      "        \"text_365\",\n",
      "        \"text_366\",\n",
      "        \"text_367\",\n",
      "        \"text_368\",\n",
      "        \"text_369\",\n",
      "        \"text_370\",\n",
      "        \"text_371\",\n",
      "        \"text_372\",\n",
      "        \"text_373\",\n",
      "        \"text_374\",\n",
      "        \"text_375\",\n",
      "        \"text_376\",\n",
      "        \"text_377\",\n",
      "        \"text_379\",\n",
      "        \"text_380\",\n",
      "        \"text_381\",\n",
      "        \"text_382\",\n",
      "        \"text_383\",\n",
      "        \"text_384\",\n",
      "        \"text_385\",\n",
      "        \"text_386\",\n",
      "        \"text_387\",\n",
      "        \"text_388\",\n",
      "        \"text_389\",\n",
      "        \"text_390\",\n",
      "        \"text_391\",\n",
      "        \"text_392\",\n",
      "        \"text_393\",\n",
      "        \"text_394\",\n",
      "        \"text_395\",\n",
      "        \"text_396\",\n",
      "        \"text_397\",\n",
      "        \"text_398\",\n",
      "        \"text_399\",\n",
      "        \"text_400\",\n",
      "        \"text_401\",\n",
      "        \"text_402\",\n",
      "        \"text_403\",\n",
      "        \"text_404\",\n",
      "        \"text_405\",\n",
      "        \"text_406\",\n",
      "        \"text_407\",\n",
      "        \"text_408\",\n",
      "        \"text_409\",\n",
      "        \"text_410\",\n",
      "        \"text_411\",\n",
      "        \"text_412\",\n",
      "        \"text_413\",\n",
      "        \"text_414\",\n",
      "        \"text_415\",\n",
      "        \"text_416\",\n",
      "        \"text_417\",\n",
      "        \"text_418\",\n",
      "        \"text_419\",\n",
      "        \"text_420\",\n",
      "        \"text_421\",\n",
      "        \"text_422\",\n",
      "        \"text_423\",\n",
      "        \"text_424\",\n",
      "        \"text_425\",\n",
      "        \"text_427\",\n",
      "        \"text_428\",\n",
      "        \"text_429\",\n",
      "        \"text_430\",\n",
      "        \"text_431\",\n",
      "        \"text_432\",\n",
      "        \"text_433\",\n",
      "        \"text_434\",\n",
      "        \"text_435\",\n",
      "        \"text_436\",\n",
      "        \"text_437\",\n",
      "        \"text_438\",\n",
      "        \"text_439\",\n",
      "        \"text_440\",\n",
      "        \"text_441\",\n",
      "        \"text_442\",\n",
      "        \"text_443\",\n",
      "        \"text_444\",\n",
      "        \"text_445\",\n",
      "        \"text_446\",\n",
      "        \"text_447\",\n",
      "        \"text_450\",\n",
      "        \"text_451\",\n",
      "        \"text_452\",\n",
      "        \"text_453\",\n",
      "        \"text_454\",\n",
      "        \"text_455\",\n",
      "        \"text_456\",\n",
      "        \"text_457\",\n",
      "        \"text_458\",\n",
      "        \"text_459\",\n",
      "        \"text_460\",\n",
      "        \"text_461\",\n",
      "        \"text_462\",\n",
      "        \"text_463\",\n",
      "        \"text_465\",\n",
      "        \"text_466\",\n",
      "        \"text_467\",\n",
      "        \"text_468\",\n",
      "        \"text_469\",\n",
      "        \"text_470\",\n",
      "        \"text_471\",\n",
      "        \"text_472\",\n",
      "        \"text_473\",\n",
      "        \"text_474\",\n",
      "        \"text_475\",\n",
      "        \"text_476\",\n",
      "        \"text_477\",\n",
      "        \"text_478\",\n",
      "        \"text_479\",\n",
      "        \"text_480\",\n",
      "        \"text_481\",\n",
      "        \"text_482\",\n",
      "        \"text_483\",\n",
      "        \"text_484\",\n",
      "        \"text_485\",\n",
      "        \"text_486\",\n",
      "        \"text_487\",\n",
      "        \"text_488\",\n",
      "        \"text_489\",\n",
      "        \"text_490\",\n",
      "        \"text_491\",\n",
      "        \"text_492\",\n",
      "        \"text_494\",\n",
      "        \"text_495\",\n",
      "        \"text_496\",\n",
      "        \"text_497\",\n",
      "        \"text_498\",\n",
      "        \"text_499\",\n",
      "        \"text_500\",\n",
      "        \"text_501\",\n",
      "        \"text_502\",\n",
      "        \"text_503\",\n",
      "        \"text_504\",\n",
      "        \"text_505\",\n",
      "        \"text_506\",\n",
      "        \"text_507\",\n",
      "        \"text_509\",\n",
      "        \"text_510\",\n",
      "        \"text_511\",\n",
      "        \"text_512\",\n",
      "        \"text_513\",\n",
      "        \"text_514\",\n",
      "        \"text_515\",\n",
      "        \"text_517\",\n",
      "        \"text_518\",\n",
      "        \"text_519\",\n",
      "        \"text_520\",\n",
      "        \"text_521\",\n",
      "        \"text_522\",\n",
      "        \"text_523\",\n",
      "        \"text_524\",\n",
      "        \"text_525\",\n",
      "        \"text_526\",\n",
      "        \"text_528\",\n",
      "        \"text_529\",\n",
      "        \"text_530\",\n",
      "        \"text_531\",\n",
      "        \"text_532\",\n",
      "        \"text_533\",\n",
      "        \"text_534\",\n",
      "        \"text_535\",\n",
      "        \"text_536\",\n",
      "        \"text_537\",\n",
      "        \"text_538\",\n",
      "        \"text_539\",\n",
      "        \"text_541\",\n",
      "        \"text_542\",\n",
      "        \"text_543\",\n",
      "        \"text_544\",\n",
      "        \"text_545\",\n",
      "        \"text_546\",\n",
      "        \"text_547\",\n",
      "        \"text_548\",\n",
      "        \"text_549\",\n",
      "        \"text_550\",\n",
      "        \"text_551\",\n",
      "        \"text_552\",\n",
      "        \"text_553\",\n",
      "        \"text_555\",\n",
      "        \"text_556\",\n",
      "        \"text_557\",\n",
      "        \"text_558\",\n",
      "        \"text_559\",\n",
      "        \"text_560\",\n",
      "        \"text_561\",\n",
      "        \"text_562\",\n",
      "        \"text_563\",\n",
      "        \"text_564\",\n",
      "        \"text_565\",\n",
      "        \"text_567\",\n",
      "        \"text_568\",\n",
      "        \"text_570\",\n",
      "        \"text_571\",\n",
      "        \"text_572\",\n",
      "        \"text_573\",\n",
      "        \"text_574\",\n",
      "        \"text_575\",\n",
      "        \"text_576\",\n",
      "        \"text_577\",\n",
      "        \"text_578\",\n",
      "        \"text_579\",\n",
      "        \"text_580\",\n",
      "        \"text_581\",\n",
      "        \"text_582\",\n",
      "        \"text_583\",\n",
      "        \"text_584\",\n",
      "        \"text_585\",\n",
      "        \"text_586\",\n",
      "        \"text_587\",\n",
      "        \"text_588\",\n",
      "        \"text_589\",\n",
      "        \"text_590\",\n",
      "        \"text_591\",\n",
      "        \"text_592\",\n",
      "        \"text_594\",\n",
      "        \"text_595\",\n",
      "        \"text_596\",\n",
      "        \"text_597\",\n",
      "        \"text_598\",\n",
      "        \"text_599\",\n",
      "        \"text_600\",\n",
      "        \"text_601\",\n",
      "        \"text_603\",\n",
      "        \"text_604\",\n",
      "        \"text_605\",\n",
      "        \"text_606\",\n",
      "        \"text_607\",\n",
      "        \"text_608\",\n",
      "        \"text_609\",\n",
      "        \"text_610\",\n",
      "        \"text_611\",\n",
      "        \"text_612\",\n",
      "        \"text_613\",\n",
      "        \"text_614\",\n",
      "        \"text_615\",\n",
      "        \"text_616\",\n",
      "        \"text_617\",\n",
      "        \"text_618\",\n",
      "        \"text_619\",\n",
      "        \"text_621\",\n",
      "        \"text_622\",\n",
      "        \"text_623\",\n",
      "        \"text_624\",\n",
      "        \"text_625\",\n",
      "        \"text_626\",\n",
      "        \"text_627\",\n",
      "        \"text_628\",\n",
      "        \"text_629\",\n",
      "        \"text_631\",\n",
      "        \"text_632\",\n",
      "        \"text_633\",\n",
      "        \"text_635\",\n",
      "        \"text_636\",\n",
      "        \"text_638\",\n",
      "        \"text_639\",\n",
      "        \"text_640\",\n",
      "        \"text_641\",\n",
      "        \"text_642\",\n",
      "        \"text_644\",\n",
      "        \"text_645\",\n",
      "        \"text_646\",\n",
      "        \"text_647\",\n",
      "        \"text_648\",\n",
      "        \"text_650\",\n",
      "        \"text_652\",\n",
      "        \"text_653\",\n",
      "        \"text_654\",\n",
      "        \"text_655\",\n",
      "        \"text_656\",\n",
      "        \"text_657\",\n",
      "        \"text_658\",\n",
      "        \"text_659\",\n",
      "        \"text_660\",\n",
      "        \"text_661\",\n",
      "        \"text_662\",\n",
      "        \"text_663\",\n",
      "        \"text_664\",\n",
      "        \"text_665\",\n",
      "        \"text_666\",\n",
      "        \"text_667\",\n",
      "        \"text_669\",\n",
      "        \"text_671\",\n",
      "        \"text_672\",\n",
      "        \"text_673\",\n",
      "        \"text_675\",\n",
      "        \"text_676\",\n",
      "        \"text_677\",\n",
      "        \"text_678\",\n",
      "        \"text_679\",\n",
      "        \"text_680\",\n",
      "        \"text_681\",\n",
      "        \"text_682\",\n",
      "        \"text_683\",\n",
      "        \"text_684\",\n",
      "        \"text_686\",\n",
      "        \"text_687\",\n",
      "        \"text_688\",\n",
      "        \"text_689\",\n",
      "        \"text_691\",\n",
      "        \"text_692\",\n",
      "        \"text_693\",\n",
      "        \"text_694\",\n",
      "        \"text_695\",\n",
      "        \"text_696\",\n",
      "        \"text_697\",\n",
      "        \"text_698\",\n",
      "        \"text_699\",\n",
      "        \"text_700\",\n",
      "        \"text_701\",\n",
      "        \"text_702\",\n",
      "        \"text_703\",\n",
      "        \"text_704\",\n",
      "        \"text_705\",\n",
      "        \"text_706\",\n",
      "        \"text_707\",\n",
      "        \"text_708\",\n",
      "        \"text_709\",\n",
      "        \"text_710\",\n",
      "        \"text_711\",\n",
      "        \"text_712\",\n",
      "        \"text_713\",\n",
      "        \"text_714\",\n",
      "        \"text_715\",\n",
      "        \"text_716\",\n",
      "        \"text_717\",\n",
      "        \"text_718\",\n",
      "        \"text_719\",\n",
      "        \"text_721\",\n",
      "        \"text_722\",\n",
      "        \"text_723\",\n",
      "        \"text_725\",\n",
      "        \"text_726\",\n",
      "        \"text_727\",\n",
      "        \"text_728\",\n",
      "        \"text_729\",\n",
      "        \"text_731\",\n",
      "        \"text_732\",\n",
      "        \"text_733\",\n",
      "        \"text_734\",\n",
      "        \"text_736\",\n",
      "        \"text_738\",\n",
      "        \"text_739\",\n",
      "        \"text_740\",\n",
      "        \"text_741\",\n",
      "        \"text_742\",\n",
      "        \"text_743\",\n",
      "        \"text_744\",\n",
      "        \"text_745\",\n",
      "        \"text_747\",\n",
      "        \"text_748\",\n",
      "        \"text_749\",\n",
      "        \"text_750\",\n",
      "        \"text_751\",\n",
      "        \"text_753\",\n",
      "        \"text_754\",\n",
      "        \"text_755\",\n",
      "        \"text_756\",\n",
      "        \"text_757\",\n",
      "        \"text_758\",\n",
      "        \"text_759\",\n",
      "        \"text_760\",\n",
      "        \"text_761\",\n",
      "        \"text_762\",\n",
      "        \"text_763\",\n",
      "        \"text_764\",\n",
      "        \"text_765\",\n",
      "        \"text_766\",\n",
      "        \"text_767\",\n",
      "        \"ProductTitleNL.char_count\",\n",
      "        \"ProductTitleNL.word_count\",\n",
      "        \"ProductTitleNL.capital_ratio\",\n",
      "        \"ProductTitleNL.lower_ratio\",\n",
      "        \"ProductTitleNL.digit_ratio\",\n",
      "        \"ProductTitleNL.special_ratio\",\n",
      "        \"ProductTitleNL.symbol_count.?\",\n",
      "        \"ProductTitleNL.symbol_count. \",\n",
      "        \"ProductTitleNL.symbol_ratio. \",\n",
      "        \"ProductTitleNL.symbol_ratio.-\",\n",
      "        \"ProductDescriptionNL.char_count\",\n",
      "        \"ProductDescriptionNL.word_count\",\n",
      "        \"ProductDescriptionNL.capital_ratio\",\n",
      "        \"ProductDescriptionNL.lower_ratio\",\n",
      "        \"ProductDescriptionNL.digit_ratio\",\n",
      "        \"ProductDescriptionNL.special_ratio\",\n",
      "        \"ProductDescriptionNL.symbol_count..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio..\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.:\",\n",
      "        \"ProductDescriptionNL.symbol_count. \",\n",
      "        \"ProductDescriptionNL.symbol_ratio. \",\n",
      "        \"ProductDescriptionNL.symbol_count./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio./\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.-\"\n",
      "    ],\n",
      "    \"skewed\": [\n",
      "        \"NumberOfProductsInPackage\",\n",
      "        \"PackageHeight\",\n",
      "        \"PackageLength\",\n",
      "        \"PackageWeight\",\n",
      "        \"PackageWidth\",\n",
      "        \"ProductHeight\",\n",
      "        \"ProductLength\",\n",
      "        \"ProductWeight\",\n",
      "        \"ProductWidth\",\n",
      "        \"text_1\",\n",
      "        \"text_21\",\n",
      "        \"text_22\",\n",
      "        \"text_25\",\n",
      "        \"text_27\",\n",
      "        \"text_28\",\n",
      "        \"text_82\",\n",
      "        \"text_90\",\n",
      "        \"text_163\",\n",
      "        \"text_182\",\n",
      "        \"text_184\",\n",
      "        \"text_193\",\n",
      "        \"text_208\",\n",
      "        \"text_210\",\n",
      "        \"text_211\",\n",
      "        \"text_217\",\n",
      "        \"text_224\",\n",
      "        \"text_229\",\n",
      "        \"text_240\",\n",
      "        \"text_265\",\n",
      "        \"text_270\",\n",
      "        \"text_274\",\n",
      "        \"text_281\",\n",
      "        \"text_289\",\n",
      "        \"text_292\",\n",
      "        \"text_297\",\n",
      "        \"text_306\",\n",
      "        \"text_319\",\n",
      "        \"text_340\",\n",
      "        \"text_378\",\n",
      "        \"text_426\",\n",
      "        \"text_448\",\n",
      "        \"text_449\",\n",
      "        \"text_464\",\n",
      "        \"text_493\",\n",
      "        \"text_508\",\n",
      "        \"text_516\",\n",
      "        \"text_527\",\n",
      "        \"text_540\",\n",
      "        \"text_554\",\n",
      "        \"text_566\",\n",
      "        \"text_569\",\n",
      "        \"text_593\",\n",
      "        \"text_602\",\n",
      "        \"text_620\",\n",
      "        \"text_630\",\n",
      "        \"text_634\",\n",
      "        \"text_637\",\n",
      "        \"text_643\",\n",
      "        \"text_649\",\n",
      "        \"text_651\",\n",
      "        \"text_668\",\n",
      "        \"text_670\",\n",
      "        \"text_674\",\n",
      "        \"text_685\",\n",
      "        \"text_690\",\n",
      "        \"text_720\",\n",
      "        \"text_724\",\n",
      "        \"text_730\",\n",
      "        \"text_735\",\n",
      "        \"text_737\",\n",
      "        \"text_746\",\n",
      "        \"text_752\",\n",
      "        \"ProductTitleNL.symbol_count.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.!\",\n",
      "        \"ProductTitleNL.symbol_ratio.%\",\n",
      "        \"ProductTitleNL.symbol_count.*\",\n",
      "        \"ProductTitleNL.symbol_ratio.*\",\n",
      "        \"ProductTitleNL.symbol_count.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.&\",\n",
      "        \"ProductTitleNL.symbol_ratio.#\",\n",
      "        \"ProductTitleNL.symbol_count..\",\n",
      "        \"ProductTitleNL.symbol_ratio..\",\n",
      "        \"ProductTitleNL.symbol_count.:\",\n",
      "        \"ProductTitleNL.symbol_ratio.:\",\n",
      "        \"ProductTitleNL.symbol_count./\",\n",
      "        \"ProductTitleNL.symbol_ratio./\",\n",
      "        \"ProductTitleNL.symbol_count.-\",\n",
      "        \"ProductTitleNL.symbol_ratio.=\",\n",
      "        \"ProductDescriptionNL.symbol_count.!\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.!\",\n",
      "        \"ProductDescriptionNL.symbol_count.?\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.?\",\n",
      "        \"ProductDescriptionNL.symbol_count.@\",\n",
      "        \"ProductDescriptionNL.symbol_count.%\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.%\",\n",
      "        \"ProductDescriptionNL.symbol_count.*\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.*\",\n",
      "        \"ProductDescriptionNL.symbol_count.&\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.&\",\n",
      "        \"ProductDescriptionNL.symbol_count.#\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.#\",\n",
      "        \"ProductDescriptionNL.symbol_count.:\",\n",
      "        \"ProductDescriptionNL.symbol_count.;\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.;\",\n",
      "        \"ProductDescriptionNL.symbol_count.-\",\n",
      "        \"ProductDescriptionNL.symbol_count.=\",\n",
      "        \"ProductDescriptionNL.symbol_ratio.=\"\n",
      "    ],\n",
      "    \"onehot\": [\n",
      "        \"hasTitle\",\n",
      "        \"hasDesc\",\n",
      "        \"has_image_url\",\n",
      "        \"PackageHeightUnit\",\n",
      "        \"PackageLengthUnit\",\n",
      "        \"PackageWeightUnit\",\n",
      "        \"PackageWidthUnit\",\n",
      "        \"ProductHeightUnit\",\n",
      "        \"ProductWeightUnit\",\n",
      "        \"ProductWidthUnit\",\n",
      "        \"ProductTitleNL.symbol_count.%\",\n",
      "        \"ProductTitleNL.symbol_count.#\",\n",
      "        \"ProductTitleNL.symbol_count.=\"\n",
      "    ],\n",
      "    \"embed\": [\n",
      "        \"BrickName\",\n",
      "        \"ChunkName\",\n",
      "        \"BrandName\",\n",
      "        \"Colour\",\n",
      "        \"Material\",\n",
      "        \"ProductLengthUnit\",\n",
      "        \"image_url\"\n",
      "    ],\n",
      "    \"language\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data for neural network has: 2672 examples, 869 features (862 vector, 7 embedding, 0 language)\n",
      "Training neural network for up to 500 epochs...\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (numeric_block): NumericBlock(\n",
      "    (body): Dense(None -> 749, Activation(relu))\n",
      "  )\n",
      "  (embed_blocks): HybridSequential(\n",
      "    (0): EmbedBlock(\n",
      "      (body): Embedding(11 -> 6, float32)\n",
      "    )\n",
      "    (1): EmbedBlock(\n",
      "      (body): Embedding(12 -> 6, float32)\n",
      "    )\n",
      "    (2): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (3): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "    (4): EmbedBlock(\n",
      "      (body): Embedding(80 -> 18, float32)\n",
      "    )\n",
      "    (5): EmbedBlock(\n",
      "      (body): Embedding(5 -> 3, float32)\n",
      "    )\n",
      "    (6): EmbedBlock(\n",
      "      (body): Embedding(102 -> 21, float32)\n",
      "    )\n",
      "  )\n",
      "  (output_block): WideAndDeepBlock(\n",
      "    (deep): FeedforwardBlock(\n",
      "      (body): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (1): Dropout(p = 0.1, axes=())\n",
      "        (2): Dense(None -> 256, Activation(relu))\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (4): Dropout(p = 0.1, axes=())\n",
      "        (5): Dense(None -> 128, Activation(relu))\n",
      "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (7): Dropout(p = 0.1, axes=())\n",
      "        (8): Dense(None -> 2, linear)\n",
      "      )\n",
      "    )\n",
      "    (wide): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n",
      "Epoch 0.  Train loss: 0.4523653, Val accuracy: 0.918918918918919\n",
      "Epoch 10.  Train loss: 0.10806645, Val accuracy: 0.9222972972972973\n",
      "Epoch 20.  Train loss: 0.039327353, Val accuracy: 0.9155405405405406\n",
      "Best model found in epoch 17. Val accuracy: 0.9256756756756757\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L2/model.pkl\n",
      "\t0.9309\t = Validation accuracy score\n",
      "\t105.8s\t = Training runtime\n",
      "\t2.84s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0942761\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0942761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00187196\tvalid_set's binary_error: 0.0505051\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.047138\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.047138\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0505051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0639731\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0673401\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0639731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00187196\tvalid_set's binary_error: 0.0909091\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0841751\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0841751\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0841751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00149757\tvalid_set's binary_error: 0.0841751\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00112317\tvalid_set's binary_error: 0.0673401\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0808081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00336952\tvalid_set's binary_error: 0.0707071\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0740741\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0707071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00224635\tvalid_set's binary_error: 0.0740741\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0673401\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0673401\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F9 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F9 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00149701\tvalid_set's binary_error: 0.0810811\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0743243\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0709459\n",
      "[200]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0675676\n",
      "[250]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0675676\n",
      "[300]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n",
      "[350]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n",
      "[400]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F10 with 'num_gpus': 1, 'num_cpus': 6\n",
      "\tTraining S1F10 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Training Gradient Boosting Model for 10000 rounds...\n",
      "with the following hyperparameter settings:\n",
      "{'num_threads': -1, 'learning_rate': 0.03, 'objective': 'binary', 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain_set's binary_error: 0.00112275\tvalid_set's binary_error: 0.0641892\n",
      "[100]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n",
      "[150]\ttrain_set's binary_error: 0\tvalid_set's binary_error: 0.0641892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t0.9323\t = Validation accuracy score\n",
      "\t698.22s\t = Training runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L2/utils/oof.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 6\n",
      "Ensemble size: 34\n",
      "Ensemble weights: \n",
      "[0.97058824 0.02941176 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L3/model.pkl\n",
      "\t0.9363\t = Validation accuracy score\n",
      "\t1.94s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 3779.51s ...\n",
      "Loading: model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBM_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/CatBoost_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/XGBoost_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/WeightedEnsemble_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsUnif_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/KNeighborsDist_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBM_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/CatBoost_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/XGBoost_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/NeuralNetMXNet_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/WeightedEnsemble_L3/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/WeightedEnsemble_L3/model.pkl\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Saving model2_tabular_featurizedV2/models/trainer.pkl\n",
      "Saving model2_tabular_featurizedV2/learner.pkl\n",
      "Saving model2_tabular_featurizedV2/predictor.pkl\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"model2_tabular_featurizedV2/\")\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model2_tabular_featurizedV2\"\n",
    "\n",
    "predictor = TabularPredictor(label='Unwanted', path=model_path,verbosity=3)\\\n",
    ".fit(train_data,\n",
    "     time_limit=None,\n",
    "     presets='best_quality',\n",
    "#      num_bag_folds=20,\n",
    "#      num_bag_sets=2,\n",
    "#      num_stack_levels=2,\n",
    "     ag_args_fit = {\"num_gpus\": 1},\n",
    "     hyperparameters=default_hp_config,\n",
    "     save_space=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "intensive-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Loading: model2_tabular_featurizedV2/predictor.pkl\n",
      "Loading: model2_tabular_featurizedV2/learner.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/trainer.pkl\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(\"model2_tabular_featurizedV2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "accompanied-bench",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>44.652199</td>\n",
       "      <td>2197.848386</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>1.936054</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.935984</td>\n",
       "      <td>41.752961</td>\n",
       "      <td>1955.977745</td>\n",
       "      <td>0.473415</td>\n",
       "      <td>92.479565</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.935984</td>\n",
       "      <td>44.173504</td>\n",
       "      <td>2103.432767</td>\n",
       "      <td>2.893958</td>\n",
       "      <td>239.934587</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.932951</td>\n",
       "      <td>41.741159</td>\n",
       "      <td>2073.390486</td>\n",
       "      <td>0.461613</td>\n",
       "      <td>209.892306</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.932615</td>\n",
       "      <td>42.468031</td>\n",
       "      <td>2083.940129</td>\n",
       "      <td>1.188485</td>\n",
       "      <td>220.441949</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.932278</td>\n",
       "      <td>41.768987</td>\n",
       "      <td>2561.714390</td>\n",
       "      <td>0.489441</td>\n",
       "      <td>698.216211</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetMXNet_BAG_L2</td>\n",
       "      <td>0.930930</td>\n",
       "      <td>44.123288</td>\n",
       "      <td>1969.302377</td>\n",
       "      <td>2.843742</td>\n",
       "      <td>105.804198</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.929919</td>\n",
       "      <td>3.157239</td>\n",
       "      <td>174.007613</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>1.913096</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.929245</td>\n",
       "      <td>0.448932</td>\n",
       "      <td>73.982421</td>\n",
       "      <td>0.448932</td>\n",
       "      <td>73.982421</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.928908</td>\n",
       "      <td>1.226604</td>\n",
       "      <td>199.342825</td>\n",
       "      <td>1.226604</td>\n",
       "      <td>199.342825</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.928235</td>\n",
       "      <td>0.440864</td>\n",
       "      <td>150.388684</td>\n",
       "      <td>0.440864</td>\n",
       "      <td>150.388684</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.928235</td>\n",
       "      <td>16.888403</td>\n",
       "      <td>242.480609</td>\n",
       "      <td>16.888403</td>\n",
       "      <td>242.480609</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetMXNet_BAG_L1</td>\n",
       "      <td>0.927898</td>\n",
       "      <td>2.702849</td>\n",
       "      <td>98.112097</td>\n",
       "      <td>2.702849</td>\n",
       "      <td>98.112097</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.927561</td>\n",
       "      <td>0.495598</td>\n",
       "      <td>805.394017</td>\n",
       "      <td>0.495598</td>\n",
       "      <td>805.394017</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.926550</td>\n",
       "      <td>44.943756</td>\n",
       "      <td>1867.146789</td>\n",
       "      <td>3.664210</td>\n",
       "      <td>3.648609</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.926213</td>\n",
       "      <td>44.940023</td>\n",
       "      <td>1867.176450</td>\n",
       "      <td>3.660477</td>\n",
       "      <td>3.678270</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.925202</td>\n",
       "      <td>58.575354</td>\n",
       "      <td>2087.760391</td>\n",
       "      <td>17.295808</td>\n",
       "      <td>224.262212</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.924865</td>\n",
       "      <td>45.033911</td>\n",
       "      <td>1865.987705</td>\n",
       "      <td>3.754365</td>\n",
       "      <td>2.489525</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>2.895803</td>\n",
       "      <td>280.868510</td>\n",
       "      <td>2.895803</td>\n",
       "      <td>280.868510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.923518</td>\n",
       "      <td>3.609571</td>\n",
       "      <td>3.644480</td>\n",
       "      <td>3.609571</td>\n",
       "      <td>3.644480</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.923518</td>\n",
       "      <td>3.725556</td>\n",
       "      <td>3.533052</td>\n",
       "      <td>3.725556</td>\n",
       "      <td>3.533052</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.922170</td>\n",
       "      <td>3.705659</td>\n",
       "      <td>2.225936</td>\n",
       "      <td>3.705659</td>\n",
       "      <td>2.225936</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.922170</td>\n",
       "      <td>44.962081</td>\n",
       "      <td>1865.743689</td>\n",
       "      <td>3.682535</td>\n",
       "      <td>2.245510</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>3.730911</td>\n",
       "      <td>2.441898</td>\n",
       "      <td>3.730911</td>\n",
       "      <td>2.441898</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsDist_BAG_L2</td>\n",
       "      <td>0.825135</td>\n",
       "      <td>41.984197</td>\n",
       "      <td>1864.071372</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.573193</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.818733</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>0.539295</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>0.539295</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsUnif_BAG_L2</td>\n",
       "      <td>0.818396</td>\n",
       "      <td>41.984218</td>\n",
       "      <td>1864.073599</td>\n",
       "      <td>0.704672</td>\n",
       "      <td>0.575420</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.814016</td>\n",
       "      <td>0.704097</td>\n",
       "      <td>0.544355</td>\n",
       "      <td>0.704097</td>\n",
       "      <td>0.544355</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val  pred_time_val     fit_time  \\\n",
       "0       WeightedEnsemble_L3   0.936321      44.652199  2197.848386   \n",
       "1         LightGBMXT_BAG_L2   0.935984      41.752961  1955.977745   \n",
       "2           CatBoost_BAG_L2   0.935984      44.173504  2103.432767   \n",
       "3           LightGBM_BAG_L2   0.932951      41.741159  2073.390486   \n",
       "4            XGBoost_BAG_L2   0.932615      42.468031  2083.940129   \n",
       "5      LightGBMLarge_BAG_L2   0.932278      41.768987  2561.714390   \n",
       "6     NeuralNetMXNet_BAG_L2   0.930930      44.123288  1969.302377   \n",
       "7       WeightedEnsemble_L2   0.929919       3.157239   174.007613   \n",
       "8         LightGBMXT_BAG_L1   0.929245       0.448932    73.982421   \n",
       "9            XGBoost_BAG_L1   0.928908       1.226604   199.342825   \n",
       "10          LightGBM_BAG_L1   0.928235       0.440864   150.388684   \n",
       "11   NeuralNetFastAI_BAG_L1   0.928235      16.888403   242.480609   \n",
       "12    NeuralNetMXNet_BAG_L1   0.927898       2.702849    98.112097   \n",
       "13     LightGBMLarge_BAG_L1   0.927561       0.495598   805.394017   \n",
       "14  RandomForestGini_BAG_L2   0.926550      44.943756  1867.146789   \n",
       "15  RandomForestEntr_BAG_L2   0.926213      44.940023  1867.176450   \n",
       "16   NeuralNetFastAI_BAG_L2   0.925202      58.575354  2087.760391   \n",
       "17    ExtraTreesGini_BAG_L2   0.924865      45.033911  1865.987705   \n",
       "18          CatBoost_BAG_L1   0.924528       2.895803   280.868510   \n",
       "19  RandomForestEntr_BAG_L1   0.923518       3.609571     3.644480   \n",
       "20  RandomForestGini_BAG_L1   0.923518       3.725556     3.533052   \n",
       "21    ExtraTreesEntr_BAG_L1   0.922170       3.705659     2.225936   \n",
       "22    ExtraTreesEntr_BAG_L2   0.922170      44.962081  1865.743689   \n",
       "23    ExtraTreesGini_BAG_L1   0.919137       3.730911     2.441898   \n",
       "24    KNeighborsDist_BAG_L2   0.825135      41.984197  1864.071372   \n",
       "25    KNeighborsDist_BAG_L1   0.818733       0.704700     0.539295   \n",
       "26    KNeighborsUnif_BAG_L2   0.818396      41.984218  1864.073599   \n",
       "27    KNeighborsUnif_BAG_L1   0.814016       0.704097     0.544355   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.005279           1.936054            3       True   \n",
       "1                 0.473415          92.479565            2       True   \n",
       "2                 2.893958         239.934587            2       True   \n",
       "3                 0.461613         209.892306            2       True   \n",
       "4                 1.188485         220.441949            2       True   \n",
       "5                 0.489441         698.216211            2       True   \n",
       "6                 2.843742         105.804198            2       True   \n",
       "7                 0.005458           1.913096            2       True   \n",
       "8                 0.448932          73.982421            1       True   \n",
       "9                 1.226604         199.342825            1       True   \n",
       "10                0.440864         150.388684            1       True   \n",
       "11               16.888403         242.480609            1       True   \n",
       "12                2.702849          98.112097            1       True   \n",
       "13                0.495598         805.394017            1       True   \n",
       "14                3.664210           3.648609            2       True   \n",
       "15                3.660477           3.678270            2       True   \n",
       "16               17.295808         224.262212            2       True   \n",
       "17                3.754365           2.489525            2       True   \n",
       "18                2.895803         280.868510            1       True   \n",
       "19                3.609571           3.644480            1       True   \n",
       "20                3.725556           3.533052            1       True   \n",
       "21                3.705659           2.225936            1       True   \n",
       "22                3.682535           2.245510            2       True   \n",
       "23                3.730911           2.441898            1       True   \n",
       "24                0.704651           0.573193            2       True   \n",
       "25                0.704700           0.539295            1       True   \n",
       "26                0.704672           0.575420            2       True   \n",
       "27                0.704097           0.544355            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          28  \n",
       "1          17  \n",
       "2          21  \n",
       "3          18  \n",
       "4          25  \n",
       "5          27  \n",
       "6          26  \n",
       "7          14  \n",
       "8           3  \n",
       "9          11  \n",
       "10          4  \n",
       "11         10  \n",
       "12         12  \n",
       "13         13  \n",
       "14         19  \n",
       "15         20  \n",
       "16         24  \n",
       "17         22  \n",
       "18          7  \n",
       "19          6  \n",
       "20          5  \n",
       "21          9  \n",
       "22         23  \n",
       "23          8  \n",
       "24         16  \n",
       "25          2  \n",
       "26         15  \n",
       "27          1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "played-scale",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: model2_tabular_featurizedV2/models/RandomForestGini_BAG_L1/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      Y\n",
       "1      N\n",
       "2      Y\n",
       "3      Y\n",
       "4      Y\n",
       "      ..\n",
       "633    Y\n",
       "634    Y\n",
       "635    N\n",
       "636    N\n",
       "637    Y\n",
       "Name: Unwanted, Length: 638, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred = predictor.predict(valid_data, model=\"RandomForestGini_BAG_L1\")\n",
    "test_pred = predictor.predict(test_data,  model=\"RandomForestGini_BAG_L1\")\n",
    "valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "resistant-winner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sub_name = \"submission1_model2_tabular_featurized_V2_RandomForestGini_BAG_L1\"\n",
    "os.makedirs(sub_name, exist_ok=True)\n",
    "np.savetxt(sub_name+\"/\"+\"valid.txt\", valid_pred, fmt='%s')\n",
    "np.savetxt(sub_name+\"/\"+\"test.txt\", test_pred, fmt='%s')\n",
    "\n",
    "os.system(\"cd {} &&zip {}.zip test.txt valid.txt\".format(sub_name, sub_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
